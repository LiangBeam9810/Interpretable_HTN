{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "%aimport ecg_get_data\n",
    "%aimport Models\n",
    "%aimport train_test_validat\n",
    "%aimport self_attention\n",
    "%aimport ecg_plot\n",
    "%aimport Net\n",
    "%aimport select_dataset\n",
    "%aimport relat_abs_Net\n",
    "import relat_abs_Net\n",
    "import select_dataset\n",
    "import Models \n",
    "from tqdm import tqdm\n",
    "import Net\n",
    "from train_test_validat import *\n",
    "from self_attention import *\n",
    "import  ecg_get_data \n",
    "import matplotlib.pyplot as plt\n",
    "import ecg_plot\n",
    "\n",
    "import torch\n",
    "import torch.utils.data as Data\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "import time\n",
    "import os\n",
    "import gc\n",
    "\n",
    "random_seed = 2\n",
    "torch.manual_seed(random_seed)    # reproducible\n",
    "torch.cuda.manual_seed_all(random_seed)\n",
    "random.seed(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "\n",
    "time_str = time.strftime(\"%Y%m%d_%H%M%S\", time.localtime()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "model_path = './model/'+time_str\n",
    "log_path = './log/'+  time_str\n",
    "ECG_root = '/workspace/data/Preprocess_HTN/data/ECG'\n",
    "EcgChannles_num = 12\n",
    "EcgLength_num = 5000\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "data = select_dataset.splite_dataset('/workspace/data/Preprocess_HTN/data/',True)\n",
    "test_list = data.__get_test_file_list__(False)\n",
    "# print(valid_list)\n",
    "valid_list,train_list,addition_train_list = data.__get_VT_file_list__(0,False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_infos_df = data.__read_infos__(test_list)\n",
    "test_infos_df = test_infos_df.dropna(subset=['years']) #删除years== nan\n",
    "test_infos_df.loc[~(test_infos_df['years'].str.contains('岁')),'years']='0岁' #不含有岁的（天周月）改为\"0岁\"\n",
    "test_infos_df['years'].replace(regex=True,inplace=True,to_replace=r'岁',value=r'') #删除\"岁\"\n",
    "test_infos_df['gender'].replace(regex=True,inplace=True,to_replace=r'男',value=r'1') #替换男\n",
    "test_infos_df['gender'].replace(regex=True,inplace=True,to_replace=r'女',value=r'0') #替换男\n",
    "\n",
    "train_infos_df = data.__read_infos__(train_list)\n",
    "train_infos_df = train_infos_df.dropna(subset=['years']) #删除years== nan\n",
    "train_infos_df.loc[~(train_infos_df['years'].str.contains('岁')),'years']='0岁' #不含有岁的（天周月）改为\"0岁\"\n",
    "train_infos_df['years'].replace(regex=True,inplace=True,to_replace=r'岁',value=r'') #删除\"岁\"\n",
    "train_infos_df['gender'].replace(regex=True,inplace=True,to_replace=r'男',value=r'1') #替换男\n",
    "train_infos_df['gender'].replace(regex=True,inplace=True,to_replace=r'女',value=r'0') #替换男\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.subplot2grid((1,2),(0,0))\n",
    "(pd.to_numeric(test_infos_df.years[test_infos_df['ECG_path'].str.contains('_HTN')])).plot(kind = 'kde')\n",
    "(pd.to_numeric(test_infos_df.years[test_infos_df['ECG_path'].str.contains('_NHTN')])).plot(kind = 'kde')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_infos_df.gender[test_infos_df['ECG_path'].str.contains('_HTN')].value_counts().plot.pie(autopct = '%1.2f%%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_infos_df.gender[test_infos_df['ECG_path'].str.contains('_NHTN')].value_counts().plot.pie(autopct = '%1.2f%%') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.subplot2grid((1,2),(0,0))\n",
    "(pd.to_numeric(train_infos_df.years[train_infos_df['ECG_path'].str.contains('_HTN')])).plot(kind = 'kde')\n",
    "(pd.to_numeric(train_infos_df.years[train_infos_df['ECG_path'].str.contains('_NHTN')])).plot(kind = 'kde')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_infos_df.gender[train_infos_df['ECG_path'].str.contains('_HTN')].value_counts().plot.pie(autopct = '%1.2f%%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_infos_df.gender[train_infos_df['ECG_path'].str.contains('_NHTN')].value_counts().plot.pie(autopct = '%1.2f%%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "for fold in range(FOLDS):\n",
    "    #每个人fold都重新抽取\n",
    "    NET[fold].to(DEVICE)\n",
    "    valid_list,train_list,addition_train_list = data.__get_VT_file_list__(0.2,True)\n",
    "    valid_Dataset = ecg_get_data.ECG_Dataset(ECG_root,valid_list,EcgChannles_num,EcgLength_num)\n",
    "    train_Dataset = ecg_get_data.ECG_Dataset(ECG_root,train_list,EcgChannles_num,EcgLength_num,ECG_root,addition_train_list)\n",
    "    \n",
    "    train_dataloader = Data.DataLoader(dataset=train_Dataset, batch_size=BATCH_SIZE, shuffle=True,num_workers=16,pin_memory=True)\n",
    "    valid_dataloader = Data.DataLoader(dataset=valid_Dataset, batch_size=BATCH_SIZE, shuffle=True,num_workers=16,pin_memory=True)\n",
    "    #test_dataloader = Data.DataLoader(dataset=test_Dataset, batch_size=25, shuffle=True,num_workers=1,pin_memory=True)\n",
    "    early_stopping = EarlyStopping(PATIENCE, verbose=True, model_path=model_path, delta=0, positive=False)\n",
    "    optimizer  = torch.optim.Adam(NET[fold].parameters(), lr=LR,weight_decay=1e-2)  \n",
    "    \n",
    "    warm_up_iter = 6\n",
    "    T_max = 16\t# 周期\n",
    "    lr_max = 1e-3\t# 最大值\n",
    "    lr_min = 1e-5\t# 最小值\n",
    "    lambda0 = lambda cur_iter: (cur_iter / warm_up_iter)*lr_max if  cur_iter < warm_up_iter else \\\n",
    "        (lr_min + 0.5*(lr_max-lr_min)*(1.0+math.cos( (cur_iter-warm_up_iter)/(T_max-warm_up_iter)*math.pi)))/0.1\n",
    "    scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda0)\n",
    "    criterion = torch.nn.CrossEntropyLoss()   \n",
    "\n",
    "    for epoch in range(1,EPOCHS):\n",
    "        time_all=0\n",
    "        start_time = time.time()\n",
    "        y_true,y_pred,train_loss,train_acc = train_model(train_dataloader, NET[fold], criterion, optimizer,DEVICE) # type: ignore # 训练模型\n",
    "        time_all = time.time()-start_time\n",
    "        C0 = confusion_matrix(y_true,y_pred)\n",
    "        F1_score_train =f1_score(y_true, y_pred, average='macro')#F1分数\n",
    "        y_true,y_pred,validate_loss,validate_acc = eval_model(valid_dataloader,criterion,NET[fold],DEVICE) # 验证模型\n",
    "        F1_score_valid =f1_score(y_true, y_pred, average='macro')#F1分数\n",
    "        writer.add_scalars(main_tag=str(fold)+'_Loss',tag_scalar_dict={'train': train_loss,'validate': validate_loss},global_step=epoch)\n",
    "        writer.add_scalars(main_tag=str(fold)+'_Accuracy',tag_scalar_dict={'train': train_acc,'validate': validate_acc},global_step=epoch)\n",
    "        writer.add_scalars(main_tag=str(fold)+'_LearningRate',tag_scalar_dict={'LR': optimizer.state_dict()['param_groups'][0]['lr']},global_step=epoch)\n",
    "        writer.add_scalars(main_tag=str(fold)+'_F1_score',tag_scalar_dict={'train':F1_score_train,'validate': F1_score_valid},global_step=epoch)\n",
    "        print('- Epoch: %d - Train_loss: %.5f - Train_acc: %.5f - F1 score: %.5f - Val_loss: %.5f - Val_acc: %.5f - F1 score: %.5f - T_Time: %.5f' %(epoch,train_loss,train_acc,F1_score_train,validate_loss,validate_acc,F1_score_valid,time_all))\n",
    "        print('当前学习率：%.8f' %optimizer.state_dict()['param_groups'][0]['lr'])\n",
    "        C1 = confusion_matrix(y_true,y_pred)\n",
    "        print('train:\\n',C0)\n",
    "        print('validate:\\n',C1)\n",
    "        \n",
    "        scheduler.step() # 学习率迭代\n",
    "        #是否满足早停法条件\n",
    "        if(early_stopping(validate_loss,NET[fold],fold)):\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "\n",
    "    print('Fold %d Training Finished' %(fold+1))\n",
    "    torch.cuda.empty_cache()# 清空显卡cuda\n",
    "print('Training Finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "test_Dataset = ecg_get_data.ECG_Dataset(ECG_root,test_list,EcgChannles_num,EcgLength_num)\n",
    "ECG,label = test_Dataset.__getitem__(1)\n",
    "#inf,path = train_Dataset.get_basic_inf(55)\n",
    "#ecg_plot.plot(ECG*3500/1000, sample_rate = 500, title = \"test\",row_height= 10,show_grid=True,show_separate_line=True)\n",
    "label\n",
    "#ecg_plot.save_as_png(inf[1],'/workspace/data/OneDrive - mail.hfut.edu.cn/ECG/Interpretable_HTN//PNG_ECG/',dpi = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "FOLDS = 1\n",
    "EPOCHS = 200  \n",
    "PATIENCE = 100\n",
    "LR = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter   \n",
    "os.makedirs(model_path, exist_ok=True)\n",
    "writer = SummaryWriter(log_path)\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()# 清空显卡cuda\n",
    "#NET = [Models.channels_split_ATT_CNN_(mark=True) for i in range(FOLDS)]\n",
    "# NET = [\n",
    "#     Net.channels_branch_CNN(True)\n",
    "#     ]\n",
    "# NET = [ \n",
    "#         Models.channels_split_ATT_CNN_linear_avgpool_for_grad(mark=True,extract_dim=16,hdim=32)\n",
    "#       ]\n",
    "# NET = [Models.resnet18(12,64,2)]\n",
    "#NET = [Models.channels_split_ATT_CNN_(mark=True) for i in range(FOLDS)]\n",
    "#NET =[Models.Informer(1)]\n",
    "NET = [Net.channels_branch_CNN(True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pytorch_warmup as warmup\n",
    "\n",
    "torch.cuda.empty_cache()# 清空显卡cuda\n",
    "for fold in range(FOLDS):\n",
    "    NET[fold].to(DEVICE)\n",
    "    train_size= int(0.8*len(x_Dataset))\n",
    "    validate_size=(len(x_Dataset)) - train_size\n",
    "    train_Dataset,valid_Dataset=torch.utils.data.random_split(x_Dataset,[train_size,validate_size])    # type: ignore\n",
    "    train_dataloader = Data.DataLoader(dataset=train_Dataset, batch_size=BATCH_SIZE, shuffle=True,num_workers=5,pin_memory=True)\n",
    "    valid_dataloader = Data.DataLoader(dataset=valid_Dataset, batch_size=BATCH_SIZE, shuffle=True,num_workers=5,pin_memory=True)\n",
    "    test_dataloader = Data.DataLoader(dataset=test_Dataset, batch_size=25, shuffle=True,num_workers=5,pin_memory=True)\n",
    "    early_stopping = EarlyStopping(PATIENCE, verbose=True, model_path=model_path, delta=0)    \n",
    "    optimizer  = torch.optim.Adadelta(NET[fold].parameters(), lr=LR,weight_decay=1e-2)  \n",
    "    lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[EPOCHS//5], gamma=0.1)\n",
    "    warmup_scheduler = warmup.UntunedLinearWarmup(optimizer)\n",
    "    warmup_scheduler.last_step = -1 # initialize the step counter\n",
    "    \n",
    "    # scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 7, gamma=0.5)#等间隔调整学习率\n",
    "    # scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer=optimizer,base_lr=1e-8,max_lr=1e-3,step_size_down=16,step_size_up=16 ,cycle_momentum=False)\n",
    "    criterion = torch.nn.CrossEntropyLoss()   \n",
    "    \n",
    "    best_loss = 3\n",
    "    for epoch in range(1,EPOCHS):\n",
    "        time_all=0\n",
    "        start_time = time.time()\n",
    "        lr_scheduler.step(epoch-1)\n",
    "        warmup_scheduler.dampen()\n",
    "        \n",
    "        train_loss,train_acc = train_model(train_dataloader, NET[fold], criterion, optimizer,DEVICE) # 训练模型\n",
    "\n",
    "        time_all = time.time()-start_time\n",
    "        y_true,y_pred,validate_loss,validate_acc = eval_model(valid_dataloader,criterion,NET[fold],DEVICE) # 测试模型\n",
    "        y_true_test,y_pred_test,loss_test,acc_test = eval_model(valid_dataloader,criterion,NET[fold],DEVICE) # 测试模型\n",
    "        F1_score =f1_score(y_true, y_pred, average='macro')#F1分数\n",
    "        F1_score_test =f1_score(y_true_test, y_pred_test, average='macro')#F1分数\n",
    "        writer.add_scalars(main_tag=str(fold)+'_Loss',tag_scalar_dict={'train': train_loss,'validate': validate_loss,'test': loss_test},global_step=epoch)\n",
    "        writer.add_scalars(main_tag=str(fold)+'_Accuracy',tag_scalar_dict={'train': train_acc,'validate': validate_acc,'test': acc_test},global_step=epoch)\n",
    "        writer.add_scalars(main_tag=str(fold)+'_LearningRate',tag_scalar_dict={'LR': optimizer.state_dict()['param_groups'][0]['lr']},global_step=epoch)\n",
    "        writer.add_scalars(main_tag=str(fold)+'_F1_score',tag_scalar_dict={'validate': F1_score,'test':F1_score_test},global_step=epoch)\n",
    "        print('- Epoch: %d - Train_loss: %.5f - Train_acc: %.5f - Val_loss: %.5f - Val_acc: %5f - T_Time: %.5f' %(epoch,train_loss,train_acc,validate_loss,validate_acc,time_all))\n",
    "        print('F1 score: %f' %(F1_score))\n",
    "        print('当前学习率：%.8f' %optimizer.state_dict()['param_groups'][0]['lr'])\n",
    "        C1 = confusion_matrix(y_true,y_pred)\n",
    "        C2 = confusion_matrix(y_true_test,y_pred_test)\n",
    "        print('validate:',C1,'  dtest:' ,C2)\n",
    "        if validate_loss < best_loss:\n",
    "            best_loss = validate_loss\n",
    "            print('Find better model in Epoch {0}, saving model.'.format(epoch))\n",
    "            #torch.save(NET[fold],  model_path+'/all_best_model_' + str(fold) + '.pt')  # 保存最优模型\n",
    "            torch.save(NET[fold].state_dict(), model_path+'/parameter_best_model_' + str(fold) + '.pt')\n",
    "        if C2[1,1]>300 and C2[0,0]>\n",
    "        #是否满足早停法条件\n",
    "        if(early_stopping(F1_score,NET[fold],fold)):\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "\n",
    "    print('Fold %d Training Finished' %(fold+1))\n",
    "    torch.cuda.empty_cache()# 清空显卡cuda\n",
    "print('Training Finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class exectal_attention(nn.Module):\n",
    "    def __init__(self,in_channels,out_channels,menmory_dim):\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.menmory_dim = menmory_dim\n",
    "        self.M_k = nn.Linear(self.out_channels, self.menmory_dim,bias=False)\n",
    "        self.M_v = nn.Linear(self.menmory_dim, self.out_channels,bias=False)\n",
    "        self.query = nn.Linear(self.in_channels, self.out_channels,bias=False)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "    def l1_norm(self,aij,dim=2):\n",
    "        aij_norm= aij/torch.sum(aij,dim=dim)  # type: ignore\n",
    "        return aij_norm\n",
    "    def forward(self, x):\n",
    "        x = self.query(x)\n",
    "        attn = self.M_k(x)\n",
    "        attn = self.softmax(attn)\n",
    "        attn = self.l1_norm(attn,dim=2)\n",
    "        out = self.M_v(x)\n",
    "        return out,attn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "%aimport ecg_get_data\n",
    "%aimport Models\n",
    "%aimport train_test_validat\n",
    "%aimport self_attention\n",
    "%aimport ECGplot\n",
    "%aimport cam\n",
    "%aimport Net\n",
    "%aimport select_dataset\n",
    "import select_dataset\n",
    "import Net\n",
    "import random\n",
    "import Models \n",
    "from train_test_validat import *\n",
    "import  ecg_get_data \n",
    "import ECGplot\n",
    "import cam \n",
    "\n",
    "import torch\n",
    "import torch.utils.data as Data\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "random_seed = 2\n",
    "torch.manual_seed(random_seed)    # reproducible\n",
    "torch.cuda.manual_seed_all(random_seed)\n",
    "random.seed(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "\n",
    "test_npy_path =  './data/test/' #路径\n",
    "xml_path = './xml/xml/'\n",
    "lead_index = ['I', 'II', 'III', 'aVR', 'aVL', 'aVF', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6']\n",
    "EcgChannles_num = 12\n",
    "EcgLength_num = 5000\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = select_dataset.splite_dataset('/workspace/data/Preprocess_HTN/data/',True)\n",
    "test_list = data.__get_test_file_list__(False)\n",
    "test_Dataset = ecg_get_data.ECG_Dataset('/workspace/data/Preprocess_HTN/data/ECG',test_list,EcgChannles_num,EcgLength_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testmodel = (Net.MLBFNet(True,res = True,se = True,Dropout_rate = 0.25)).to(DEVICE)  # type: ignore\n",
    "# testmodel = (Models.resnet18(12,64,2)).to(DEVICE)\n",
    "testmodel.load_state_dict(torch.load(\"./model/20221025_113645/parameter_EarlyStoping_0.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST_BATCH_SIZE = test_Dataset.npys.__len__()\n",
    "test_dataloader = Data.DataLoader(dataset=test_Dataset, batch_size=512)\n",
    "\n",
    "test_acc = []   \n",
    "criterion = torch.nn.CrossEntropyLoss() \n",
    "possibility,y_true,y_pred,test_loss,test_acc, = eval_model_possibility(test_dataloader,criterion,testmodel,DEVICE) # 测试模型\n",
    "print('loss =',test_loss,'acc =',test_acc)\n",
    "print('f1_macro =',f1_score(y_true, y_pred, average='macro')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "cm = confusion_matrix(y_true=y_true, y_pred=y_pred)\n",
    "print(\"Confusion Matrix: \")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "possibility = np.array(possibility)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cleanlab\n",
    "fake_label = cleanlab.filter.find_label_issues(y_true,possibility)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(y_pred.__len__()):\n",
    "    print('fake lable',fake_label[i])\n",
    "    print('y_pred',y_pred[i])\n",
    "    print('y_true',y_true[i])\n",
    "    print(possibility[i])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()# 清空显卡cuda\n",
    "# NET = [\n",
    "#     Net.channels_branch_CNN(True,res = True,se = True,Dropout_rate = 0.25)\n",
    "# ]\n",
    "# NET = [Net.channels_branch_CNN(True,res = True,se = True,Dropout_rate = 0.25) ] # type: ignore\n",
    "NET = [relat_abs_Net.MLBFNet_GUR() ] # type: ignore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.randn(1, 12,5000)\n",
    "output = NET[0](input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\n",
      " orginal   fliter department&age\n",
      "  33342       8479   \n",
      "\t\n",
      " orginal   fliter duplicated\n",
      "   509        423    \n",
      "\t\n",
      " orginal   fliter duplicated\n",
      "   8479       7043   \n",
      "\t\n",
      "       HTN  NHTN \n",
      "test   423   423 \n",
      "npys:{%d} 846\n"
     ]
    }
   ],
   "source": [
    "data = select_dataset.splite_dataset('/workspace/data/Preprocess_HTN/data/',True)\n",
    "test_list = data.__get_test_file_list__(shuffer=False,filter_department='外科')\n",
    "ECG_root = '/workspace/data/Preprocess_HTN/data/ECG'\n",
    "EcgChannles_num = 12\n",
    "EcgLength_num = 5000\n",
    "test_Dataset = ecg_get_data.ECG_Dataset(ECG_root,test_list,EcgChannles_num,EcgLength_num,position_encode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer1 = pd.read_csv('./20221111_034149_test.csv')\n",
    "answer1.rename(columns={'pred':'pred1'},inplace=True) \n",
    "answer2 = pd.read_csv('./20221111_090319_test.csv')\n",
    "answer2.rename(columns={'pred':'pred2'},inplace=True) \n",
    "answer3 = pd.read_csv('./20221111_144243_test.csv')\n",
    "answer3.rename(columns={'pred':'pred3'},inplace=True) \n",
    "answer4 = pd.read_csv('./20221112_150151_test.csv')\n",
    "answer4.rename(columns={'pred':'pred4'},inplace=True) \n",
    "answer1 = pd.merge(answer1,answer2.loc[:,['file name','pred2']],how='outer',on='file name')\n",
    "answer1 = pd.merge(answer1,answer3.loc[:,['file name','pred3']],how='outer',on='file name')\n",
    "answer1 = pd.merge(answer1,answer4.loc[:,['file name','pred4']],how='outer',on='file name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>file name</th>\n",
       "      <th>true</th>\n",
       "      <th>pred1</th>\n",
       "      <th>pred2</th>\n",
       "      <th>pred3</th>\n",
       "      <th>pred4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>21-1-1059_HTN.npy</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>21-1-105_HTN.npy</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>21-1-1191_HTN.npy</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>21-1-1303_HTN.npy</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>21-1-1305_HTN.npy</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>841</th>\n",
       "      <td>841</td>\n",
       "      <td>21-1-2983_NHTN.npy</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>842</th>\n",
       "      <td>842</td>\n",
       "      <td>21-1-298_NHTN.npy</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>843</th>\n",
       "      <td>843</td>\n",
       "      <td>21-1-2997_NHTN.npy</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>844</th>\n",
       "      <td>844</td>\n",
       "      <td>21-1-3001_NHTN.npy</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>845</th>\n",
       "      <td>845</td>\n",
       "      <td>21-1-3037_NHTN.npy</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>846 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0           file name  true  pred1  pred2  pred3  pred4\n",
       "0             0   21-1-1059_HTN.npy     1      0      0      0      0\n",
       "1             1    21-1-105_HTN.npy     1      1      1      1      1\n",
       "2             2   21-1-1191_HTN.npy     1      1      1      1      1\n",
       "3             3   21-1-1303_HTN.npy     1      1      0      1      1\n",
       "4             4   21-1-1305_HTN.npy     1      1      1      1      1\n",
       "..          ...                 ...   ...    ...    ...    ...    ...\n",
       "841         841  21-1-2983_NHTN.npy     0      0      0      0      0\n",
       "842         842   21-1-298_NHTN.npy     0      0      0      0      0\n",
       "843         843  21-1-2997_NHTN.npy     0      0      0      0      0\n",
       "844         844  21-1-3001_NHTN.npy     0      1      0      1      0\n",
       "845         845  21-1-3037_NHTN.npy     0      0      0      0      0\n",
       "\n",
       "[846 rows x 7 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer1.insert(loc=len(answer1.columns), column='sum', value=(answer1['pred1']+answer1['pred2']+answer1['pred3']+answer1['pred4']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTN_errs = answer1[((answer1['true']==1)&(answer1['sum']<2))|((answer1['true']==0)&(answer1['sum']>1))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>file name</th>\n",
       "      <th>true</th>\n",
       "      <th>pred1</th>\n",
       "      <th>pred2</th>\n",
       "      <th>pred3</th>\n",
       "      <th>pred4</th>\n",
       "      <th>sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>21-1-1059_HTN.npy</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>21-1-1489_HTN.npy</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>21-1-1775_HTN.npy</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>21-1-187_HTN.npy</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>21-1-2036_HTN.npy</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>812</th>\n",
       "      <td>812</td>\n",
       "      <td>21-1-286_NHTN.npy</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>816</th>\n",
       "      <td>816</td>\n",
       "      <td>21-1-2881_NHTN.npy</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>834</th>\n",
       "      <td>834</td>\n",
       "      <td>21-1-2958_NHTN.npy</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>837</th>\n",
       "      <td>837</td>\n",
       "      <td>21-1-2973_NHTN.npy</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>844</th>\n",
       "      <td>844</td>\n",
       "      <td>21-1-3001_NHTN.npy</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>146 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0           file name  true  pred1  pred2  pred3  pred4  sum\n",
       "0             0   21-1-1059_HTN.npy     1      0      0      0      0    0\n",
       "11           11   21-1-1489_HTN.npy     1      0      0      0      0    0\n",
       "13           13   21-1-1775_HTN.npy     1      0      0      0      0    0\n",
       "16           16    21-1-187_HTN.npy     1      0      0      0      0    0\n",
       "18           18   21-1-2036_HTN.npy     1      0      0      0      0    0\n",
       "..          ...                 ...   ...    ...    ...    ...    ...  ...\n",
       "812         812   21-1-286_NHTN.npy     0      1      0      1      0    2\n",
       "816         816  21-1-2881_NHTN.npy     0      1      1      1      1    4\n",
       "834         834  21-1-2958_NHTN.npy     0      1      0      1      0    2\n",
       "837         837  21-1-2973_NHTN.npy     0      0      1      0      1    2\n",
       "844         844  21-1-3001_NHTN.npy     0      1      0      1      0    2\n",
       "\n",
       "[146 rows x 8 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTN_errs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 127/146 [08:41<01:13,  3.84s/it]/opt/conda/lib/python3.7/site-packages/ecg_plot/ecg_plot.py:248: UserWarning: Glyph 57344 (\\ue000) missing from current font.\n",
      "  plt.savefig(path + file_name + '.png', dpi = dpi, bbox_inches=layout)\n",
      "100%|██████████| 146/146 [09:55<00:00,  4.08s/it]\n"
     ]
    }
   ],
   "source": [
    "for index in tqdm((HTN_errs['Unnamed: 0']).tolist()):\n",
    "    inf = (data.__read_info__(HTN_errs.loc[index,'file name'])).reset_index(drop=True)\n",
    "    ECG,label = test_Dataset.__getitem__(index)\n",
    "    file_name = inf['name'][0]+'_'+inf['gender'][0]+'_'+str(inf['years'][0])+'_'+inf['department'][0] +'_'+(inf['diagnose'][0]).replace('/','-')+'_'+inf['ID'][0] +'_'+inf['date'][0] \n",
    "    ecg_plot.plot(ECG*3500/1000, sample_rate = 500, title = file_name,row_height= 10,show_grid=True,show_separate_line=True)\n",
    "    file_name = str(HTN_errs.loc[index,'file name'])+'_'+file_name+'_'+str(HTN_errs.loc[index,'sum'])\n",
    "    ecg_plot.save_as_png(file_name,'./ERR/',dpi = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTN_not_errs = answer1[~(((answer1['true']==1)&(answer1['sum']<2))|((answer1['true']==0)&(answer1['sum']>1)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 700/700 [44:52<00:00,  3.85s/it]\n"
     ]
    }
   ],
   "source": [
    "for index in tqdm((HTN_not_errs['Unnamed: 0']).tolist()):\n",
    "    inf = (data.__read_info__(HTN_not_errs.loc[index,'file name'])).reset_index(drop=True)\n",
    "    ECG,label = test_Dataset.__getitem__(index)\n",
    "    file_name = inf['name'][0]+'_'+inf['gender'][0]+'_'+str(inf['years'][0])+'_'+inf['department'][0] +'_'+(inf['diagnose'][0]).replace('/','-')+'_'+inf['ID'][0] +'_'+inf['date'][0] \n",
    "    ecg_plot.plot(ECG*3500/1000, sample_rate = 500, title = file_name,row_height= 10,show_grid=True,show_separate_line=True)\n",
    "    file_name = str(HTN_not_errs.loc[index,'file name'])+'_'+file_name+'_'+str(HTN_not_errs.loc[index,'sum'])\n",
    "    ecg_plot.save_as_png(file_name,'./Right/',dpi = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>file name</th>\n",
       "      <th>true</th>\n",
       "      <th>pred1</th>\n",
       "      <th>pred2</th>\n",
       "      <th>pred3</th>\n",
       "      <th>pred4</th>\n",
       "      <th>sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>21-1-105_HTN.npy</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>21-1-1191_HTN.npy</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>21-1-1303_HTN.npy</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>21-1-1305_HTN.npy</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>21-1-1311_HTN.npy</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>840</th>\n",
       "      <td>840</td>\n",
       "      <td>21-1-2982_NHTN.npy</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>841</th>\n",
       "      <td>841</td>\n",
       "      <td>21-1-2983_NHTN.npy</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>842</th>\n",
       "      <td>842</td>\n",
       "      <td>21-1-298_NHTN.npy</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>843</th>\n",
       "      <td>843</td>\n",
       "      <td>21-1-2997_NHTN.npy</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>845</th>\n",
       "      <td>845</td>\n",
       "      <td>21-1-3037_NHTN.npy</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>700 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0           file name  true  pred1  pred2  pred3  pred4  sum\n",
       "1             1    21-1-105_HTN.npy     1      1      1      1      1    4\n",
       "2             2   21-1-1191_HTN.npy     1      1      1      1      1    4\n",
       "3             3   21-1-1303_HTN.npy     1      1      0      1      1    3\n",
       "4             4   21-1-1305_HTN.npy     1      1      1      1      1    4\n",
       "5             5   21-1-1311_HTN.npy     1      1      1      1      1    4\n",
       "..          ...                 ...   ...    ...    ...    ...    ...  ...\n",
       "840         840  21-1-2982_NHTN.npy     0      0      0      0      0    0\n",
       "841         841  21-1-2983_NHTN.npy     0      0      0      0      0    0\n",
       "842         842   21-1-298_NHTN.npy     0      0      0      0      0    0\n",
       "843         843  21-1-2997_NHTN.npy     0      0      0      0      0    0\n",
       "845         845  21-1-3037_NHTN.npy     0      0      0      0      0    0\n",
       "\n",
       "[700 rows x 8 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTN_not_errs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num</th>\n",
       "      <th>name</th>\n",
       "      <th>years</th>\n",
       "      <th>gender</th>\n",
       "      <th>department</th>\n",
       "      <th>diagnose</th>\n",
       "      <th>ID</th>\n",
       "      <th>date</th>\n",
       "      <th>ECG_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1594</th>\n",
       "      <td>252</td>\n",
       "      <td>卓举乐</td>\n",
       "      <td>39</td>\n",
       "      <td>男</td>\n",
       "      <td>肝胆胰血管外科病房</td>\n",
       "      <td>胆总管结石伴急性胆管炎</td>\n",
       "      <td>847344</td>\n",
       "      <td>2021-01-06 09:30:46</td>\n",
       "      <td>21-1-252_NHTN.npy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      num name  years gender department     diagnose      ID  \\\n",
       "1594  252  卓举乐     39      男  肝胆胰血管外科病房  胆总管结石伴急性胆管炎  847344   \n",
       "\n",
       "                     date           ECG_path  \n",
       "1594  2021-01-06 09:30:46  21-1-252_NHTN.npy  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.__read_info__('21-1-252_NHTN.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
