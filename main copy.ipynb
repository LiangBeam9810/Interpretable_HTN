{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "%aimport ecg_get_data\n",
    "%aimport Models\n",
    "%aimport train_test_validat\n",
    "%aimport self_attention\n",
    "%aimport ECGplot\n",
    "%aimport Net\n",
    "import Models \n",
    "import Net\n",
    "from train_test_validat import *\n",
    "from self_attention import *\n",
    "import  ecg_get_data \n",
    "import matplotlib.pyplot as plt\n",
    "import ecg_plot\n",
    "\n",
    "import torch\n",
    "import torch.utils.data as Data\n",
    "import random\n",
    "\n",
    "import time\n",
    "import os\n",
    "import gc\n",
    "\n",
    "random_seed = 2\n",
    "torch.manual_seed(random_seed)    # reproducible\n",
    "torch.cuda.manual_seed_all(random_seed)\n",
    "random.seed(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "\n",
    "time_str = time.strftime(\"%Y%m%d_%H%M%S\", time.localtime()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "NVIDIA GeForce RTX 3090 Ti\n"
     ]
    }
   ],
   "source": [
    "train_npy_path =  './data/train/' #路径\n",
    "test_npy_path =  './data/test/' \n",
    "shadow_npy_folder = './data/addition/'\n",
    "xml_path = './xml/xml/'\n",
    "#lable_path = './label.npy'\n",
    "\n",
    "model_path = './model/'+time_str\n",
    "log_path = './log/'+  time_str\n",
    "\n",
    "\n",
    "EcgChannles_num = 12\n",
    "EcgLength_num = 5000\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(DEVICE)\n",
    "print(torch.cuda.get_device_name(0))# 返回gpu名字"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "npys:{%d} 100\n",
      "npys:{%d} 3866\n",
      "shadow_npys:{%d} 4461\n"
     ]
    }
   ],
   "source": [
    "test_Dataset = ecg_get_data.ECG_Dataset(test_npy_path,EcgChannles_num,EcgLength_num,xml_folder=xml_path)\n",
    "x_Dataset = ecg_get_data.ECG_Dataset(train_npy_path,EcgChannles_num,EcgLength_num,shadow_npy_folder=shadow_npy_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ECG,label = test_Dataset.__getitem__(1)\n",
    "#inf,path = train_Dataset.get_basic_inf(55)\n",
    "#ecg_plot.plot(ECG*3500/1000, sample_rate = 500, title = \"test\",row_height= 10,show_grid=True,show_separate_line=True)\n",
    "label\n",
    "#ecg_plot.save_as_png(inf[1],'/workspace/data/OneDrive - mail.hfut.edu.cn/ECG/Interpretable_HTN//PNG_ECG/',dpi = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "FOLDS = 1\n",
    "EPOCHS = 5000  \n",
    "PATIENCE = 15\n",
    "LR = 0.005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter   \n",
    "os.makedirs(model_path, exist_ok=True)\n",
    "writer = SummaryWriter(log_path)\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()# 清空显卡cuda\n",
    "#NET = [Models.channels_split_ATT_CNN_(mark=True) for i in range(FOLDS)]\n",
    "NET = [\n",
    "    Net.channels_branch_CNN(True)\n",
    "    ]\n",
    "# NET = [ \n",
    "#         Models.channels_split_ATT_CNN_linear_avgpool_for_grad(mark=True,extract_dim=16,hdim=32)\n",
    "#       ]\n",
    "# NET = [Models.resnet18(12,64,2)]\n",
    "#NET = [Models.channels_split_ATT_CNN_(mark=True) for i in range(FOLDS)]\n",
    "#NET =[Models.Informer(1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Epoch: 1 - Train_loss: 0.68618 - Train_acc: 0.55886 - Val_loss: 0.68133 - Val_acc: 0.563301 - T_Time: 57.66569\n",
      "F1 score: 0.487528\n",
      "当前学习率：0.00500000\n",
      "Find better model in Epoch 1, saving model.\n",
      "- Epoch: 2 - Train_loss: 0.67602 - Train_acc: 0.58297 - Val_loss: 0.67162 - Val_acc: 0.565705 - T_Time: 56.76784\n",
      "F1 score: 0.500958\n",
      "当前学习率：0.00500000\n",
      "Find better model in Epoch 2, saving model.\n",
      "- Epoch: 3 - Train_loss: 0.66839 - Train_acc: 0.59994 - Val_loss: 0.66955 - Val_acc: 0.549679 - T_Time: 56.21472\n",
      "F1 score: 0.514418\n",
      "当前学习率：0.00500000\n",
      "Find better model in Epoch 3, saving model.\n",
      "- Epoch: 4 - Train_loss: 0.66384 - Train_acc: 0.61716 - Val_loss: 0.65888 - Val_acc: 0.576522 - T_Time: 55.74019\n",
      "F1 score: 0.513609\n",
      "当前学习率：0.00500000\n",
      "Find better model in Epoch 4, saving model.\n",
      "EarlyStopping counter: 1 out of 15\n",
      "\n",
      "- Epoch: 5 - Train_loss: 0.65534 - Train_acc: 0.64311 - Val_loss: 0.66189 - Val_acc: 0.555689 - T_Time: 56.52486\n",
      "F1 score: 0.519360\n",
      "当前学习率：0.00500000\n",
      "- Epoch: 6 - Train_loss: 0.65073 - Train_acc: 0.65191 - Val_loss: 0.64594 - Val_acc: 0.604567 - T_Time: 56.48186\n",
      "F1 score: 0.578336\n",
      "当前学习率：0.00500000\n",
      "Find better model in Epoch 6, saving model.\n",
      "- Epoch: 7 - Train_loss: 0.64623 - Train_acc: 0.66537 - Val_loss: 0.64443 - Val_acc: 0.631811 - T_Time: 56.52908\n",
      "F1 score: 0.604615\n",
      "当前学习率：0.00500000\n",
      "Find better model in Epoch 7, saving model.\n",
      "- Epoch: 8 - Train_loss: 0.63875 - Train_acc: 0.67857 - Val_loss: 0.62357 - Val_acc: 0.679487 - T_Time: 56.74125\n",
      "F1 score: 0.657219\n",
      "当前学习率：0.00500000\n",
      "Find better model in Epoch 8, saving model.\n",
      "- Epoch: 9 - Train_loss: 0.63367 - Train_acc: 0.69573 - Val_loss: 0.63122 - Val_acc: 0.675881 - T_Time: 56.87618\n",
      "F1 score: 0.652039\n",
      "当前学习率：0.00500000\n",
      "EarlyStopping counter: 1 out of 15\n",
      "\n",
      "- Epoch: 10 - Train_loss: 0.62770 - Train_acc: 0.70459 - Val_loss: 0.62704 - Val_acc: 0.671474 - T_Time: 56.74618\n",
      "F1 score: 0.664026\n",
      "当前学习率：0.00500000\n",
      "- Epoch: 11 - Train_loss: 0.61818 - Train_acc: 0.72200 - Val_loss: 0.62790 - Val_acc: 0.698317 - T_Time: 57.13976\n",
      "F1 score: 0.706353\n",
      "当前学习率：0.00500000\n",
      "- Epoch: 12 - Train_loss: 0.60905 - Train_acc: 0.73508 - Val_loss: 0.59599 - Val_acc: 0.712740 - T_Time: 56.53066\n",
      "F1 score: 0.728680\n",
      "当前学习率：0.00500000\n",
      "Find better model in Epoch 12, saving model.\n",
      "- Epoch: 13 - Train_loss: 0.59622 - Train_acc: 0.73418 - Val_loss: 0.62533 - Val_acc: 0.623397 - T_Time: 57.29447\n",
      "F1 score: 0.566636\n",
      "当前学习率：0.00500000\n",
      "EarlyStopping counter: 1 out of 15\n",
      "\n",
      "- Epoch: 14 - Train_loss: 0.58323 - Train_acc: 0.76046 - Val_loss: 0.60891 - Val_acc: 0.677885 - T_Time: 56.24638\n",
      "F1 score: 0.622095\n",
      "当前学习率：0.00500000\n",
      "EarlyStopping counter: 2 out of 15\n",
      "\n",
      "- Epoch: 15 - Train_loss: 0.56834 - Train_acc: 0.76939 - Val_loss: 0.55445 - Val_acc: 0.757612 - T_Time: 56.43133\n",
      "F1 score: 0.750537\n",
      "当前学习率：0.00500000\n",
      "Find better model in Epoch 15, saving model.\n",
      "Validation F1 score  increase to (inf --> 0.75053717).  Saving model ...\n",
      "                    --------------------------------------------------\n",
      "\n",
      "- Epoch: 16 - Train_loss: 0.55420 - Train_acc: 0.77513 - Val_loss: 0.55596 - Val_acc: 0.747196 - T_Time: 57.08572\n",
      "F1 score: 0.752536\n",
      "当前学习率：0.00500000\n",
      "Validation F1 score  increase to (0.75053717 --> 0.75253559).  Saving model ...\n",
      "                    --------------------------------------------------\n",
      "\n",
      "- Epoch: 17 - Train_loss: 0.54677 - Train_acc: 0.77436 - Val_loss: 0.53392 - Val_acc: 0.786058 - T_Time: 56.57449\n",
      "F1 score: 0.768018\n",
      "当前学习率：0.00250000\n",
      "Find better model in Epoch 17, saving model.\n",
      "Validation F1 score  increase to (0.75253559 --> 0.76801843).  Saving model ...\n",
      "                    --------------------------------------------------\n",
      "\n",
      "- Epoch: 18 - Train_loss: 0.53665 - Train_acc: 0.79770 - Val_loss: 0.71545 - Val_acc: 0.562901 - T_Time: 56.75760\n",
      "F1 score: 0.403319\n",
      "当前学习率：0.00250000\n",
      "EarlyStopping counter: 1 out of 15\n",
      "\n",
      "- Epoch: 19 - Train_loss: 0.53392 - Train_acc: 0.79286 - Val_loss: 0.55796 - Val_acc: 0.750401 - T_Time: 56.48024\n",
      "F1 score: 0.734748\n",
      "当前学习率：0.00250000\n",
      "EarlyStopping counter: 2 out of 15\n",
      "\n",
      "- Epoch: 20 - Train_loss: 0.53065 - Train_acc: 0.79260 - Val_loss: 0.52083 - Val_acc: 0.790865 - T_Time: 56.82309\n",
      "F1 score: 0.773120\n",
      "当前学习率：0.00250000\n",
      "Find better model in Epoch 20, saving model.\n",
      "Validation F1 score  increase to (0.76801843 --> 0.77311995).  Saving model ...\n",
      "                    --------------------------------------------------\n",
      "\n",
      "- Epoch: 21 - Train_loss: 0.52150 - Train_acc: 0.80797 - Val_loss: 0.55405 - Val_acc: 0.750000 - T_Time: 56.75115\n",
      "F1 score: 0.765197\n",
      "当前学习率：0.00250000\n",
      "EarlyStopping counter: 1 out of 15\n",
      "\n",
      "- Epoch: 22 - Train_loss: 0.52038 - Train_acc: 0.79662 - Val_loss: 0.53973 - Val_acc: 0.758013 - T_Time: 56.31957\n",
      "F1 score: 0.758032\n",
      "当前学习率：0.00250000\n",
      "EarlyStopping counter: 2 out of 15\n",
      "\n",
      "- Epoch: 23 - Train_loss: 0.52043 - Train_acc: 0.80102 - Val_loss: 0.60863 - Val_acc: 0.681090 - T_Time: 56.69158\n",
      "F1 score: 0.656915\n",
      "当前学习率：0.00250000\n",
      "EarlyStopping counter: 3 out of 15\n",
      "\n",
      "- Epoch: 24 - Train_loss: 0.51389 - Train_acc: 0.80676 - Val_loss: 0.77716 - Val_acc: 0.506811 - T_Time: 56.53271\n",
      "F1 score: 0.383763\n",
      "当前学习率：0.00250000\n",
      "EarlyStopping counter: 4 out of 15\n",
      "\n",
      "- Epoch: 25 - Train_loss: 0.50807 - Train_acc: 0.81575 - Val_loss: 0.56428 - Val_acc: 0.715946 - T_Time: 56.79012\n",
      "F1 score: 0.704534\n",
      "当前学习率：0.00250000\n",
      "EarlyStopping counter: 5 out of 15\n",
      "\n",
      "- Epoch: 26 - Train_loss: 0.50042 - Train_acc: 0.82564 - Val_loss: 0.59712 - Val_acc: 0.696314 - T_Time: 56.50147\n",
      "F1 score: 0.662855\n",
      "当前学习率：0.00125000\n",
      "EarlyStopping counter: 6 out of 15\n",
      "\n",
      "- Epoch: 27 - Train_loss: 0.50247 - Train_acc: 0.82251 - Val_loss: 0.52461 - Val_acc: 0.790865 - T_Time: 56.31478\n",
      "F1 score: 0.769074\n",
      "当前学习率：0.00125000\n",
      "EarlyStopping counter: 7 out of 15\n",
      "\n",
      "- Epoch: 28 - Train_loss: 0.50115 - Train_acc: 0.81677 - Val_loss: 0.50381 - Val_acc: 0.807692 - T_Time: 56.49993\n",
      "F1 score: 0.790187\n",
      "当前学习率：0.00125000\n",
      "Find better model in Epoch 28, saving model.\n",
      "Validation F1 score  increase to (0.77311995 --> 0.79018704).  Saving model ...\n",
      "                    --------------------------------------------------\n",
      "\n",
      "- Epoch: 29 - Train_loss: 0.50616 - Train_acc: 0.81894 - Val_loss: 0.49574 - Val_acc: 0.821715 - T_Time: 55.93314\n",
      "F1 score: 0.833320\n",
      "当前学习率：0.00125000\n",
      "Find better model in Epoch 29, saving model.\n",
      "Validation F1 score  increase to (0.79018704 --> 0.83331970).  Saving model ...\n",
      "                    --------------------------------------------------\n",
      "\n",
      "- Epoch: 30 - Train_loss: 0.50379 - Train_acc: 0.82066 - Val_loss: 0.49329 - Val_acc: 0.818109 - T_Time: 56.77083\n",
      "F1 score: 0.829447\n",
      "当前学习率：0.00125000\n",
      "Find better model in Epoch 30, saving model.\n",
      "EarlyStopping counter: 1 out of 15\n",
      "\n",
      "- Epoch: 31 - Train_loss: 0.50030 - Train_acc: 0.82347 - Val_loss: 0.47967 - Val_acc: 0.835337 - T_Time: 56.82441\n",
      "F1 score: 0.822990\n",
      "当前学习率：0.00125000\n",
      "Find better model in Epoch 31, saving model.\n",
      "EarlyStopping counter: 2 out of 15\n",
      "\n",
      "- Epoch: 32 - Train_loss: 0.49056 - Train_acc: 0.83686 - Val_loss: 0.48181 - Val_acc: 0.838942 - T_Time: 56.90230\n",
      "F1 score: 0.826707\n",
      "当前学习率：0.00125000\n",
      "EarlyStopping counter: 3 out of 15\n",
      "\n",
      "- Epoch: 33 - Train_loss: 0.49654 - Train_acc: 0.82500 - Val_loss: 0.52658 - Val_acc: 0.771234 - T_Time: 56.43140\n",
      "F1 score: 0.771034\n",
      "当前学习率：0.00125000\n",
      "EarlyStopping counter: 4 out of 15\n",
      "\n",
      "- Epoch: 34 - Train_loss: 0.49126 - Train_acc: 0.82985 - Val_loss: 0.50757 - Val_acc: 0.800080 - T_Time: 57.04348\n",
      "F1 score: 0.807173\n",
      "当前学习率：0.00125000\n",
      "EarlyStopping counter: 5 out of 15\n",
      "\n",
      "- Epoch: 35 - Train_loss: 0.48987 - Train_acc: 0.83297 - Val_loss: 0.48835 - Val_acc: 0.817308 - T_Time: 55.68082\n",
      "F1 score: 0.801603\n",
      "当前学习率：0.00125000\n",
      "EarlyStopping counter: 6 out of 15\n",
      "\n",
      "- Epoch: 36 - Train_loss: 0.49077 - Train_acc: 0.83533 - Val_loss: 0.48698 - Val_acc: 0.828526 - T_Time: 55.90965\n",
      "F1 score: 0.827772\n",
      "当前学习率：0.00125000\n",
      "EarlyStopping counter: 7 out of 15\n",
      "\n",
      "- Epoch: 37 - Train_loss: 0.48906 - Train_acc: 0.83686 - Val_loss: 0.47941 - Val_acc: 0.833333 - T_Time: 56.67653\n",
      "F1 score: 0.833099\n",
      "当前学习率：0.00062500\n",
      "Find better model in Epoch 37, saving model.\n",
      "EarlyStopping counter: 8 out of 15\n",
      "\n",
      "- Epoch: 38 - Train_loss: 0.48752 - Train_acc: 0.83705 - Val_loss: 0.48189 - Val_acc: 0.821314 - T_Time: 56.85178\n",
      "F1 score: 0.817783\n",
      "当前学习率：0.00062500\n",
      "EarlyStopping counter: 9 out of 15\n",
      "\n",
      "- Epoch: 39 - Train_loss: 0.48425 - Train_acc: 0.83763 - Val_loss: 0.56191 - Val_acc: 0.724760 - T_Time: 56.80676\n",
      "F1 score: 0.677351\n",
      "当前学习率：0.00062500\n",
      "EarlyStopping counter: 10 out of 15\n",
      "\n",
      "- Epoch: 40 - Train_loss: 0.48504 - Train_acc: 0.83801 - Val_loss: 0.47509 - Val_acc: 0.841346 - T_Time: 56.79509\n",
      "F1 score: 0.829429\n",
      "当前学习率：0.00062500\n",
      "Find better model in Epoch 40, saving model.\n",
      "EarlyStopping counter: 11 out of 15\n",
      "\n",
      "- Epoch: 41 - Train_loss: 0.48489 - Train_acc: 0.84196 - Val_loss: 0.48353 - Val_acc: 0.832532 - T_Time: 56.72035\n",
      "F1 score: 0.844696\n",
      "当前学习率：0.00062500\n",
      "Validation F1 score  increase to (0.83331970 --> 0.84469578).  Saving model ...\n",
      "                    --------------------------------------------------\n",
      "\n",
      "- Epoch: 42 - Train_loss: 0.48571 - Train_acc: 0.83552 - Val_loss: 0.51539 - Val_acc: 0.787260 - T_Time: 57.22310\n",
      "F1 score: 0.762019\n",
      "当前学习率：0.00062500\n",
      "EarlyStopping counter: 1 out of 15\n",
      "\n",
      "- Epoch: 43 - Train_loss: 0.48254 - Train_acc: 0.84043 - Val_loss: 0.48649 - Val_acc: 0.809696 - T_Time: 56.72804\n",
      "F1 score: 0.819956\n",
      "当前学习率：0.00062500\n",
      "EarlyStopping counter: 2 out of 15\n",
      "\n",
      "- Epoch: 44 - Train_loss: 0.48595 - Train_acc: 0.83999 - Val_loss: 0.46860 - Val_acc: 0.841747 - T_Time: 57.06090\n",
      "F1 score: 0.842310\n",
      "当前学习率：0.00062500\n",
      "Find better model in Epoch 44, saving model.\n",
      "EarlyStopping counter: 3 out of 15\n",
      "\n",
      "- Epoch: 45 - Train_loss: 0.48265 - Train_acc: 0.83807 - Val_loss: 0.48355 - Val_acc: 0.812099 - T_Time: 56.60851\n",
      "F1 score: 0.822547\n",
      "当前学习率：0.00062500\n",
      "EarlyStopping counter: 4 out of 15\n",
      "\n",
      "- Epoch: 46 - Train_loss: 0.48163 - Train_acc: 0.84094 - Val_loss: 0.47142 - Val_acc: 0.834535 - T_Time: 55.52595\n",
      "F1 score: 0.834492\n",
      "当前学习率：0.00062500\n",
      "EarlyStopping counter: 5 out of 15\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "torch.cuda.empty_cache()# 清空显卡cuda\n",
    "for fold in range(FOLDS):\n",
    "    train_size= int(0.8*len(x_Dataset))\n",
    "    validate_size=(len(x_Dataset)) - train_size\n",
    "    train_Dataset,valid_Dataset=torch.utils.data.random_split(x_Dataset,[train_size,validate_size])    # type: ignore\n",
    "    early_stopping = EarlyStopping(PATIENCE, verbose=True, model_path=model_path, delta=0)\n",
    "    #train_dataset,valid_dataset = get_k_fold_dataset(fold=int(fold+1),x = train_x,y=train_y,k=FOLDS,random_seed = random_seed)\n",
    "    train_dataloader = Data.DataLoader(dataset=train_Dataset, batch_size=BATCH_SIZE, shuffle=True,num_workers=5,pin_memory=True)\n",
    "    valid_dataloader = Data.DataLoader(dataset=valid_Dataset, batch_size=BATCH_SIZE, shuffle=True,num_workers=5,pin_memory=True)\n",
    "    NET[fold].to(DEVICE)\n",
    "    optimizer  = torch.optim.Adadelta(NET[fold].parameters(), lr=LR,weight_decay=1e-2)  \n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 7, gamma=0.5)\n",
    "    criterion = torch.nn.CrossEntropyLoss()   \n",
    "\n",
    "    #等间隔调整学习率\n",
    "    #scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer,T_max = 24)\n",
    "    best_loss = 3\n",
    "    for epoch in range(1,EPOCHS):\n",
    "        time_all=0\n",
    "        start_time = time.time()\n",
    "        train_loss,train_acc = train_model(train_dataloader, NET[fold], criterion, optimizer,DEVICE) # 训练模型\n",
    "\n",
    "        time_all = time.time()-start_time\n",
    "        y_true,y_pred,validate_loss,validate_acc = eval_model(valid_dataloader,criterion,NET[fold],DEVICE) # 测试模型\n",
    "        F1_score =f1_score(y_true, y_pred, average='macro')#F1分数\n",
    "\n",
    "        writer.add_scalars(main_tag=str(fold)+'_Loss',tag_scalar_dict={'train': train_loss,'validate': validate_loss},global_step=epoch)\n",
    "        writer.add_scalars(main_tag=str(fold)+'_Accuracy',tag_scalar_dict={'train': train_acc,'validate': validate_acc},global_step=epoch)\n",
    "        writer.add_scalars(main_tag=str(fold)+'_LearningRate',tag_scalar_dict={'LR': optimizer.state_dict()['param_groups'][0]['lr']},global_step=epoch)\n",
    "        writer.add_scalars(main_tag=str(fold)+'_F1_score',tag_scalar_dict={'_F1_score': F1_score},global_step=epoch)\n",
    "\n",
    "        print('- Epoch: %d - Train_loss: %.5f - Train_acc: %.5f - Val_loss: %.5f - Val_acc: %5f - T_Time: %.5f' %(epoch,train_loss,train_acc,validate_loss,validate_acc,time_all))\n",
    "        print('F1 score: %f' %(F1_score))\n",
    "        print('当前学习率：%.8f' %optimizer.state_dict()['param_groups'][0]['lr'])\n",
    "\n",
    "        if validate_loss < best_loss:\n",
    "            best_loss = validate_loss\n",
    "            print('Find better model in Epoch {0}, saving model.'.format(epoch))\n",
    "            # torch.save(NET[fold],  model_path+'/all_best_model_' + str(fold) + '.pt')  # 保存最优模型\n",
    "            torch.save(NET[fold].state_dict(), model_path+'/parameter_best_model_' + str(fold) + '.pt')\n",
    "        else:\n",
    "            scheduler.step() # 学习率迭代\n",
    "        #是否满足早停法条件\n",
    "        if(early_stopping(F1_score,NET[fold],fold)):\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "\n",
    "    print('Fold %d Training Finished' %(fold+1))\n",
    "    torch.cuda.empty_cache()# 清空显卡cuda\n",
    "print('Training Finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class exectal_attention(nn.Module):\n",
    "    def __init__(self,in_channels,out_channels,menmory_dim):\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.menmory_dim = menmory_dim\n",
    "        self.M_k = nn.Linear(self.out_channels, self.menmory_dim,bias=False)\n",
    "        self.M_v = nn.Linear(self.menmory_dim, self.out_channels,bias=False)\n",
    "        self.query = nn.Linear(self.in_channels, self.out_channels,bias=False)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "    def l1_norm(self,aij,dim=2):\n",
    "        aij_norm= aij/torch.sum(aij,dim=dim)  # type: ignore\n",
    "        return aij_norm\n",
    "    def forward(self, x):\n",
    "        x = self.query(x)\n",
    "        attn = self.M_k(x)\n",
    "        attn = self.softmax(attn)\n",
    "        attn = self.l1_norm(attn,dim=2)\n",
    "        out = self.M_v(x)\n",
    "        return out,attn\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
