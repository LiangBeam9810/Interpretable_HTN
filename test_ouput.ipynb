{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "%aimport ecg_get_data\n",
    "%aimport Models\n",
    "%aimport train_test_validat\n",
    "%aimport self_attention\n",
    "%aimport ECGplot\n",
    "\n",
    "import random\n",
    "import Models \n",
    "from train_test_validat import *\n",
    "from self_attention import *\n",
    "import  ecg_get_data \n",
    "import ECGplot\n",
    "\n",
    "import torch\n",
    "import torch.utils.data as Data\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "random_seed = 2\n",
    "torch.manual_seed(random_seed)    # reproducible\n",
    "torch.cuda.manual_seed_all(random_seed)\n",
    "random.seed(random_seed)\n",
    "np.random.seed(random_seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_npy_path =  './data/test/' #路径\n",
    "xml_path = './xml/xml/'\n",
    "lead_index = ['I', 'II', 'III', 'aVR', 'aVL', 'aVF', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6']\n",
    "EcgChannles_num = 12\n",
    "EcgLength_num = 5000\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(DEVICE)\n",
    "DEVICE = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_Dataset = ecg_get_data.ECG_Dataset(test_npy_path,EcgChannles_num,EcgLength_num,xml_folder=xml_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_Dataset = ecg_get_data.ECG_Dataset_xml('./xml/',type=\"test\",EcgChannles_num = 12,EcgLength_num = 5000,addition = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testmodel = (Net.channels_branch_CNN()).to(DEVICE)\n",
    "testmodel.load_state_dict(torch.load(\"./model/20221015_101923/parameter_EarlyStoping_0.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_BATCH_SIZE = test_Dataset.npys.__len__()\n",
    "test_dataloader = Data.DataLoader(dataset=test_Dataset, batch_size=TEST_BATCH_SIZE)\n",
    "test_acc = []   \n",
    "criterion = torch.nn.CrossEntropyLoss() \n",
    "y_true,y_pred,test_loss,test_acc = eval_model(test_dataloader,criterion,testmodel,DEVICE) # 测试模型\n",
    "print('loss =',test_loss,'acc =',test_acc)\n",
    "print('f1_macro =',f1_score(y_true, y_pred, average='macro')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testmodel.eval()\n",
    "# 定义获取梯度的函数\n",
    "fmap_block = list()\n",
    "grad_block = list()\n",
    "def backward_hook(module, grad_in, grad_out):\n",
    "    grad_block.append(grad_out[0].detach())\n",
    "\n",
    "# 定义获取特征图的函数\n",
    "def farward_hook(module, input, output):\n",
    "    fmap_block.append(output)\n",
    "\n",
    "# 存放梯度和特征图\n",
    "testmodel.conv2.register_forward_hook(farward_hook)\t#正向传播\n",
    "testmodel.conv2.register_full_backward_hook(backward_hook)#反向传播"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fmap_block = list()\n",
    "grad_block = list()\n",
    "\n",
    "itme = 1\n",
    "inputs,labels = test_Dataset.__getitem__(itme)\n",
    "\n",
    "labels = labels.unsqueeze(0) # 在首位添加1维作为batchsize\n",
    "inputs = inputs.unsqueeze(0) # 在首位添加1维作为batchsize\n",
    "\n",
    "inputs = inputs.to(DEVICE)\n",
    "labels = labels.to(DEVICE)  \n",
    "\n",
    "outputs = testmodel(inputs)\n",
    "_,pred = outputs.max(1)     # 求概率最大值对应的标签\n",
    "print(\"labels: {}\".format(labels))\n",
    "print(\"predict: {}\".format(pred))\n",
    "loss = outputs[0,1]      # 网络对应于pred的类别的输出即为loss\n",
    "# loss = (testmodel.last_out)[0,pred]\n",
    "loss.backward(retain_graph=True)  #retain_graph=True，目的为是为保留该过程中计算的梯度，后续G网络更新时使用\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fmap_block[0][0].shape\n",
    "grad_block[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fmap,gradmap size = [channel,lenth]\n",
    "def caculate_cam_vlue(fmap,gradmap,original_seq_lenth = 5000):\n",
    "    weights = np.mean(gradmap,axis=1,keepdims=True)              # [channel,1],取每个通道下所有梯度的平均数为该通道的权重\n",
    "    fmap_weights = fmap * weights                                # [channel,lenth]*[channel,1] = [channel,lenth]\n",
    "    cam = fmap_weights.sum(axis = 0)                             # [1,lenth]\n",
    "    cam[cam<0] = 0 # like relu                                   #[1,lenth]\n",
    "    cam = (cam - cam.min())/(1e-7*cam.max()) # maxmin normalize  # [1,lenth]\n",
    "    #cam = (cam*gradmap).sum(axis=0) # [channel,lenth]\n",
    "    # top_idx=cam.argsort()[0:200]#min 500\n",
    "    # cam[top_idx] = 0\n",
    "    cam_tensor = torch.tensor(cam)\n",
    "    cam_tensor = (cam_tensor.unsqueeze(0)).unsqueeze(0)\n",
    "    upsampler = nn.Upsample(original_seq_lenth,mode='linear',align_corners=False)\n",
    "    cam_tensor = upsampler(cam_tensor)\n",
    "    cam = (cam_tensor[0][0]).to('cpu').detach().numpy()\n",
    "    return cam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fmap = (fmap_block[0][0]).to('cpu').detach().numpy()\n",
    "gradmap = (grad_block[0][0]).to('cpu').detach().numpy()\n",
    "cam_vlue = caculate_cam_vlue(fmap,gradmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(0,5000)\n",
    "y = cam_vlue\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(0,5000)\n",
    "y = cam_vlue\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_index = np.arange(0,EcgLength_num)\n",
    "fig, axs = plt.subplots(nrows=6, ncols=2, sharex=True,sharey=True,figsize=(23,26), constrained_layout=True)\n",
    "ecg_data = (inputs[0]).to('cpu')\n",
    "for i,ax in enumerate(axs.flat):  # type: ignore\n",
    "    attention_value_each_timestep = cam_vlue\n",
    "    #plot_y = x[1,i,:]*(4.88)\n",
    "    plot_y = np.array(ecg_data[i]*3500.)\n",
    "    ECGplot.plot_multicolored_line(fig,ax,x = x_index,y= plot_y,color_depend=attention_value_each_timestep,cmap=\"jet\",y_name = str(lead_index[i])+\" Voltage(mV)\",title = lead_index[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MaxMinNormalization(x,Max,Min):\n",
    "    x = (x - Min) / (Max - Min);\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tow head attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "itme = 6\n",
    "inputs,labels = test_Dataset.__getitem__(itme)\n",
    "inputs = inputs.unsqueeze(0)\n",
    "inputs = inputs.to(DEVICE)\n",
    "labels = labels.to(DEVICE)  \n",
    "\n",
    "outputs = testmodel(inputs)\n",
    "_,pred = outputs.max(1) # 求概率最大值对应的标签\n",
    "attention_matrix = np.zeros((2,12,1250,1250))\n",
    "attention_matrix[0,0] = (((testmodel.att1v_1.to('cpu'))[0]).detach().numpy())\n",
    "attention_matrix[0,1] = (((testmodel.att2v_1.to('cpu'))[0]).detach().numpy())\n",
    "attention_matrix[0,2] = (((testmodel.att3v_1.to('cpu'))[0]).detach().numpy())\n",
    "attention_matrix[0,3] = (((testmodel.att4v_1.to('cpu'))[0]).detach().numpy())\n",
    "attention_matrix[0,4] = (((testmodel.att5v_1.to('cpu'))[0]).detach().numpy())\n",
    "attention_matrix[0,5] = (((testmodel.att6v_1.to('cpu'))[0]).detach().numpy())\n",
    "attention_matrix[0,6] = (((testmodel.att7v_1.to('cpu'))[0]).detach().numpy())\n",
    "attention_matrix[0,7] = (((testmodel.att8v_1.to('cpu'))[0]).detach().numpy())\n",
    "attention_matrix[0,8] = (((testmodel.att9v_1.to('cpu'))[0]).detach().numpy())\n",
    "attention_matrix[0,9] = (((testmodel.att10v_1.to('cpu'))[0]).detach().numpy())\n",
    "attention_matrix[0,10] = (((testmodel.att11v_1.to('cpu'))[0]).detach().numpy())\n",
    "attention_matrix[0,11] = (((testmodel.att12v_1.to('cpu'))[0]).detach().numpy())\n",
    "\n",
    "attention_matrix[1,0] = (((testmodel.att1v_2.to('cpu'))[0]).detach().numpy())\n",
    "attention_matrix[1,1] = (((testmodel.att2v_2.to('cpu'))[0]).detach().numpy())\n",
    "attention_matrix[1,2] = (((testmodel.att3v_2.to('cpu'))[0]).detach().numpy())\n",
    "attention_matrix[1,3] = (((testmodel.att4v_2.to('cpu'))[0]).detach().numpy())\n",
    "attention_matrix[1,4] = (((testmodel.att5v_2.to('cpu'))[0]).detach().numpy())\n",
    "attention_matrix[1,5] = (((testmodel.att6v_2.to('cpu'))[0]).detach().numpy())\n",
    "attention_matrix[1,6] = (((testmodel.att7v_2.to('cpu'))[0]).detach().numpy())\n",
    "attention_matrix[1,7] = (((testmodel.att8v_2.to('cpu'))[0]).detach().numpy())\n",
    "attention_matrix[1,8] = (((testmodel.att9v_2.to('cpu'))[0]).detach().numpy())\n",
    "attention_matrix[1,9] = (((testmodel.att10v_2.to('cpu'))[0]).detach().numpy())\n",
    "attention_matrix[1,10] = (((testmodel.att11v_2.to('cpu'))[0]).detach().numpy())\n",
    "attention_matrix[1,11] = (((testmodel.att12v_2.to('cpu'))[0]).detach().numpy())\n",
    "print(labels,pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(0,1250)\n",
    "y = (attention_matrix[1,11].sum(axis=0))\n",
    "num_bins = 50\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# the histogram of the data\n",
    "n, bins, patches = ax.hist(y, 1250, density=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_matrix_normalized = MaxMinNormalization(attention_matrix,attention_matrix.max(),attention_matrix.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_matrix[1].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_matrix[1].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minimum_data = np.minimum(attention_matrix[0],attention_matrix[1])\n",
    "maximum_data = np.maximum(attention_matrix[0],attention_matrix[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=3, ncols=4, figsize=(50, 30))\n",
    "i = 0\n",
    "\n",
    "for col in range(4):\n",
    "    for row in range(3):\n",
    "        ax = axs[row, col]\n",
    "        ax.set_title(lead_index[i])\n",
    "        pcm = ax.pcolormesh(maximum_data[i],cmap='viridis')\n",
    "        i = i+1\n",
    "fig.colorbar(pcm, ax=axs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## one head attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "itme = 2\n",
    "inputs,labels = test_Dataset.__getitem__(itme)\n",
    "inputs = inputs.unsqueeze(0)\n",
    "inputs = inputs.to(DEVICE)\n",
    "labels = labels.to(DEVICE)  \n",
    "outputs = testmodel(inputs)\n",
    "_,pred = outputs.max(1) # 求概率最大值对应的标签\n",
    "attention_matrix = np.zeros((12,1250,1250))\n",
    "attention_matrix[0] = (((testmodel.attv1.to('cpu'))[0]).detach().numpy())\n",
    "attention_matrix[1] = (((testmodel.attv2.to('cpu'))[0]).detach().numpy())\n",
    "attention_matrix[2] = (((testmodel.attv3.to('cpu'))[0]).detach().numpy())\n",
    "attention_matrix[3] = (((testmodel.attv4.to('cpu'))[0]).detach().numpy())\n",
    "attention_matrix[4] = (((testmodel.attv5.to('cpu'))[0]).detach().numpy())\n",
    "attention_matrix[5] = (((testmodel.attv6.to('cpu'))[0]).detach().numpy())\n",
    "attention_matrix[6] = (((testmodel.attv7.to('cpu'))[0]).detach().numpy())\n",
    "attention_matrix[7] = (((testmodel.attv8.to('cpu'))[0]).detach().numpy())\n",
    "attention_matrix[8] = (((testmodel.attv9.to('cpu'))[0]).detach().numpy())\n",
    "attention_matrix[9] = (((testmodel.attv10.to('cpu'))[0]).detach().numpy())\n",
    "attention_matrix[10] = (((testmodel.attv11.to('cpu'))[0]).detach().numpy())\n",
    "attention_matrix[11] = (((testmodel.attv12.to('cpu'))[0]).detach().numpy())\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_matrix_normalized = MaxMinNormalization(attention_matrix,attention_matrix.max(),attention_matrix.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=3, ncols=4, figsize=(50, 30))\n",
    "i = 0\n",
    "\n",
    "for col in range(4):\n",
    "    for row in range(3):\n",
    "        ax = axs[row, col]\n",
    "        ax.set_title(lead_index[i])\n",
    "        pcm = ax.pcolormesh(attention_matrix_normalized[i],cmap='viridis',vmin=attention_matrix_normalized.min(),vmax=attention_matrix_normalized.max())\n",
    "        i = i+1\n",
    "fig.colorbar(pcm, ax=axs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get attention value for each timestep on original input sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_attention_value_for_each_timestep_from_1D_CNN_Pool(attention_matrix,seqen_lenth,kernel = 3,padding = 1,stride = 1,pooling_size = 4):\n",
    "    attention_value_each_timestep = np.zeros(seqen_lenth,) #按照原始长度创建一个一维权重序列，其中第i值个值表示原始序列中第i个点的重要性\n",
    "    each_timestep_add_counter = np.zeros(seqen_lenth,) # 会有重复累加的情况，需要记录累加次数，用于求平均值\n",
    "    attention_value_timestep = attention_matrix.sum(axis=0) #attention_matrix 是单独一个导联的att矩阵，按行相加得到每个点对产生的新序列的总权重（理解为该点的重要程度）\n",
    "    for i in range(attention_value_timestep.shape[-1]):\n",
    "        start_index = -padding + stride*pooling_size*i\n",
    "        w = kernel+pooling_size-1\n",
    "        end_index = start_index + w\n",
    "\n",
    "        if(start_index < 0): #由于有padding的存在，所以首位会超出范围padding个长度，直接限幅到0或seq_lenth即可\n",
    "            start_index = 0\n",
    "            w = end_index - start_index\n",
    "        if(end_index > seqen_lenth):\n",
    "            end_index = seqen_lenth\n",
    "            w = end_index - start_index\n",
    "        counter_i = np.ones(w,)\n",
    "        attention_i = np.repeat(attention_value_timestep[i]/w,w) #w个attention_value_timestep[i]/w\n",
    "        attention_value_each_timestep[start_index:end_index]+=attention_i\n",
    "        each_timestep_add_counter[start_index:end_index]+=counter_i\n",
    "    return attention_value_each_timestep/each_timestep_add_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ecg_plot\n",
    "#inf,path = train_Dataset.get_basic_inf(55)\n",
    "ecg_data = (inputs[0]).to('cpu')\n",
    "ecg_plot.plot(ecg_data*3500/1000, sample_rate = 500, title = \"test\",row_height= 10,show_grid=True,show_separate_line=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_top_attention_points(fig,axs,x,y,color_depend,cmap = \"jet\",y_name = \"Voltage(mV)\",title=\"\",top_num = 100):\n",
    "    ax.plot(x,y, color='black',linewidth=0.5)\n",
    "    \n",
    "    top_idx=color_depend.argsort()[::-1][0:top_num]\n",
    "    ax.scatter(top_idx, y[top_idx],s=2,c='r')\n",
    "    #fig.colorbar(line, ax=axs)\n",
    "    axs.set_xlim(x.min(), x.max())\n",
    "    axs.set_ylim(-3500, +3500)\n",
    "\n",
    "    axs.set_aspect(0.2)#用于设置轴缩放的方面，即y-unit与x-unit的比率\n",
    "    axs.xaxis.set_major_locator(plt.MultipleLocator(100))# type: ignore # 100*0.002s=0.2s = 5格\n",
    "    axs.xaxis.set_minor_locator(plt.MultipleLocator(20)) # type: ignore # 20*0.002=0.004S = 1格\n",
    "    axs.yaxis.set_major_locator(plt.MultipleLocator(500))# type: ignore # 0.1uv*500 = 0.5ms = 5格\n",
    "    axs.yaxis.set_minor_locator(plt.MultipleLocator(100))# type: ignore # 0.1uv*100 =0.1ms = 1格 \n",
    "\n",
    "    #axs.xaxis.set_major_formatter(plt.NullFormatter()) #x轴不显示刻度值/lable per 0.2s\n",
    "    axs.xaxis.set_major_formatter(lambda x, pos: str(round(0.2*(x/100.0),2))) #x轴 lable per 0.2s\n",
    "    axs.yaxis.set_major_formatter(lambda x, pos: str(x/1000.0)) # label per '0.5 mv'，turn uV to mv\n",
    "\n",
    "    axs.grid(which='major', axis='x', linewidth=0.3, linestyle='-', color='b')\n",
    "    axs.grid(which='minor', axis='x', linewidth=0.1, linestyle='-', color='b')\n",
    "    axs.grid(which='major', axis='y', linewidth=0.3, linestyle='-', color='b')\n",
    "    axs.grid(which='minor', axis='y', linewidth=0.1, linestyle='-', color='b')\n",
    "    axs.set_ylabel(y_name)\n",
    "    axs.set_title(title)\n",
    "    axs.grid(True, which='both')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_index = np.arange(0,EcgLength_num)\n",
    "fig, axs = plt.subplots(nrows=6, ncols=2, sharex=True,sharey=True,figsize=(23,26), constrained_layout=True)\n",
    "\n",
    "for i,ax in enumerate(axs.flat):  # type: ignore\n",
    "    attention_value_each_timestep = get_attention_value_for_each_timestep_from_1D_CNN_Pool(attention_matrix[1,i],5000)\n",
    "    #plot_y = x[1,i,:]*(4.88)\n",
    "    \n",
    "    plot_y = np.array(ecg_data[i]*3500.)\n",
    "    ECGplot.plot_multicolored_line(fig,ax,x = x_index,y= plot_y,color_depend=attention_value_each_timestep,cmap=\"jet\",y_name = str(lead_index[i])+\" Voltage(mV)\",title = lead_index[i])\n",
    "    plot_top_attention_points(fig,ax,x = x_index,y= plot_y,color_depend=attention_value_each_timestep,cmap=\"jet\",y_name = str(lead_index[i])+\" Voltage(mV)\",title = lead_index[i],top_num=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_index = np.arange(0,EcgLength_num)\n",
    "fig, axs = plt.subplots(nrows=6, ncols=2, sharex=True,sharey=True,figsize=(23,26), constrained_layout=True)\n",
    "\n",
    "for i,ax in enumerate(axs.flat):  # type: ignore\n",
    "    attention_value_each_timestep = get_attention_value_for_each_timestep_from_1D_CNN_Pool(attention_matrix[0,i],5000)\n",
    "    #plot_y = x[1,i,:]*(4.88)\n",
    "    plot_y = np.array(ecg_data[i]*3500.)\n",
    "    ECGplot.plot_multicolored_line(fig,ax,x = x_index,y= plot_y,color_depend=attention_value_each_timestep,cmap=\"viridis\",y_name = str(lead_index[i])+\" Voltage(mV)\",title = lead_index[i])\n",
    "    plot_top_attention_points(fig,ax,x = x_index,y= plot_y,color_depend=attention_value_each_timestep,cmap=\"jet\",y_name = str(lead_index[i])+\" Voltage(mV)\",title = lead_index[i],top_num=200)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# handle xml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HTN to npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "file_path = Path(\"./xml/2021/HTN\")\n",
    "file_list = list(file_path.glob('*.xml')) # list(images_path.glob('*.png'))\n",
    "file_list =[str(x) for x in file_list]\n",
    "# file_list.sort(key=lambda x:int(x.split('/')[-1].split('_')[0])) #按“/”分割，取最后一个，并把最后后一个按'_'分割，\n",
    "#                                                                  #按'_'分割后再取第0个，即为编号，按此排序\n",
    "for file in tqdm(file_list):\n",
    "    ecg = ecg_get_data.get_ECG_form_xml(file,12,5000)\n",
    "    np.save('./data/train/'+(file.split('/')[-1].split('.')[0])+\".npy\",ecg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NHTN to npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "file_path = Path(\"./xml/NHTN/test\")\n",
    "file_list = list(file_path.glob('*.xml')) # list(images_path.glob('*.png'))\n",
    "file_list =[str(x) for x in file_list]\n",
    "# file_list.sort(key=lambda x:int(x.split('/')[-1].split('_')[0])) #按“/”分割，取最后一个，并把最后后一个按'_'分割，\n",
    "#                                                                  #按'_'分割后再取第0个，即为编号，按此排序\n",
    "for file in tqdm(file_list[:112]):\n",
    "    ecg = ecg_get_data.get_ECG_form_xml(file,12,5000)\n",
    "    np.save('./data/test/'+(file.split('/')[-1].split('.')[0])+\".npy\",ecg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2021 xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from shutil import copyfile\n",
    "import datetime\n",
    "\n",
    "root = \"./xml/2021\"  # 文件夹路径\n",
    "HTN_path = \"./xml/2021/HTN\"  #输出文件夹路径\n",
    "NHTN_path = \"./xml/2021/NHTN\" #输出文件夹路径\n",
    "dir_list = os.listdir(root)#返回指定的文件夹包含的文件或文件夹的名字的列表\n",
    "dir_list.sort()\n",
    "for dir in dir_list:\n",
    "    dir_path = os.path.join(root,dir)\n",
    "    if(dir_path == HTN_path or dir_path == NHTN_path):#跳过输出文件夹\n",
    "        continue\n",
    "    else:\n",
    "        xls_path = os.path.join(dir_path,'ms.xls')\n",
    "        base_infor_df= pd.read_excel(xls_path)\n",
    "        base_infor_df = base_infor_df[['序号','姓名','住院号','临床诊断','检查时间']]\n",
    "        for i_tup in base_infor_df.itertuples():#遍历所有行\n",
    "            number = int(i_tup[1])\n",
    "            name = str(i_tup[2])\n",
    "            ID = str(i_tup[3]) #住院号\n",
    "            if(ID[0] == 'R'): ID = ID[1:] #解决部分住院号开头为R的问题\n",
    "            diagnos = str(i_tup[4])\n",
    "            date = str(i_tup[5])\n",
    "        \n",
    "            xml_path = os.path.join(dir_path,str(number),'1.xml')\n",
    "            xml_id = ecg_get_data.get_id_form_xml(xml_path)#获取文件中的id号 住院号\n",
    "            if(str(xml_id)!=ID or ID==''): \n",
    "                print('id error : ',ID,\"--\",xml_id,\"||\",xml_path,i_tup)\n",
    "                continue\n",
    "            else:#不相同就报错\n",
    "                #date_filename = date_tranfor(date) #转换成文件名能用的格式\n",
    "                if(diagnos.find('高血压')>-1):\n",
    "                    copy_xml_path = os.path.join(HTN_path,'21-'+dir[5:]+'-'+str(number)+'.xml')\n",
    "                else:\n",
    "                    copy_xml_path = os.path.join(NHTN_path,'21-'+dir[5:]+'-'+str(number)+'.xml')\n",
    "                copyfile(xml_path,copy_xml_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2022 xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from shutil import copyfile\n",
    "import datetime\n",
    "\n",
    "root = \"./xml/2022\"  # 文件夹路径\n",
    "HTN_path = \"./xml/2022/HTN\"  #输出文件夹路径\n",
    "NHTN_path = \"./xml/2022/NHTN\" #输出文件夹路径\n",
    "\n",
    "\n",
    "xls_path = os.path.join(root,'ms.xls')\n",
    "base_infor_df= pd.read_excel(xls_path)\n",
    "base_infor_df = base_infor_df[['序号','姓名','住院号','临床诊断','检查时间']]\n",
    "for i_tup in base_infor_df.itertuples():#遍历所有行\n",
    "    number = int(i_tup[1])\n",
    "    name = str(i_tup[2])\n",
    "    ID = str(i_tup[3]) #住院号\n",
    "    if(ID[0] == 'R'): ID = ID[1:] #解决部分住院号开头为R的问题\n",
    "    diagnos = str(i_tup[4])#\n",
    "    date = str(i_tup[5])\n",
    "        \n",
    "    xml_path = os.path.join(root,str(number),'1.xml')\n",
    "    xml_id = ecg_get_data.get_id_form_xml(xml_path)#获取文件中的id号 住院号\n",
    "    if(str(xml_id)!=ID or ID==''): \n",
    "        # print('id error : ',ID,\"--\",xml_id,\"||\",xml_path,i_tup)\n",
    "        print(ID,\"-\",xml_id,\"|\",xml_path)\n",
    "        continue\n",
    "    else:#不相同就报错\n",
    "        #date_filename = date_tranfor(date) #转换成文件名能用的格式\n",
    "        if(diagnos.find('高血压')>-1):\n",
    "            copy_xml_path = os.path.join(HTN_path,'22'+'-'+str(number)+'.xml')\n",
    "        else:\n",
    "            copy_xml_path = os.path.join(NHTN_path,'22'+'-'+str(number)+'.xml')\n",
    "        copyfile(xml_path,copy_xml_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "m = nn.AvgPool2d(56, stride=1)\n",
    "input = torch.randn(20, 64, 128, 128)\n",
    "output = m(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = output.view(output.size(0), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 提出非高血压中 年龄小于40岁的样本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from shutil import copyfile\n",
    "import datetime\n",
    "import  ecg_get_data \n",
    "import numpy as np\n",
    "\n",
    "dir_path = \"./xml/NHTN/test/\"\n",
    "xls_path = os.path.join('./xml/','22.xls')\n",
    "base_infor_df= pd.read_excel(xls_path)\n",
    "base_infor_df = base_infor_df[['序号','姓名','年龄']]\n",
    "for i_tup in (base_infor_df.itertuples()):#遍历XLS文件的所有所有行\n",
    "    number = int(i_tup[1])\n",
    "    name = str(i_tup[2])\n",
    "    year_s = str(i_tup[3])\n",
    "    if((year_s.find('岁')>-1) and int(year_s[:-1])>40): #年龄栏单位为岁，且大于40，则删除\n",
    "        xml_path = os.path.join(dir_path,'22-'+str(number)+'_NHTN.xml')\n",
    "        if(os.path.exists(xml_path)):\n",
    "          os.remove(xml_path)\n",
    "          print(xml_path)\n",
    "        else:\n",
    "            continue\n",
    "        \n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 删除在npy_ECG中 所有2个导联以上全为0 的样本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2245 [00:00<?, ?it/s]\r  1%|          | 28/2245 [00:00<00:08, 273.68it/s]\r  2%|▏         | 56/2245 [00:00<00:08, 262.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error in  ./npy_ECG/test/22-12454_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-12455_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-12456_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-12476_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-12480_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-12486_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-12487_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-12511_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-12513_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-12515_NHTN.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 83/2245 [00:00<00:08, 262.66it/s]\r  5%|▍         | 112/2245 [00:00<00:07, 270.31it/s]\r  6%|▌         | 140/2245 [00:00<00:07, 272.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error in  ./npy_ECG/test/22-12589_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-12641_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-12686_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-12705_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-12739_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-12784_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-127_NHTN.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 168/2245 [00:00<00:07, 271.00it/s]\r  9%|▊         | 196/2245 [00:00<00:07, 264.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error in  ./npy_ECG/test/22-12827_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-12865_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-132_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-133_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-15306_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-15316_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-15318_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-15319_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-15320_NHTN.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 223/2245 [00:00<00:07, 262.89it/s]\r 11%|█         | 250/2245 [00:00<00:07, 262.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error in  ./npy_ECG/test/22-15410_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-15411_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-15438_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-15441_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-15447_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-15453_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-15454_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-15461_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-15473_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-15587_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-15682_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-15683_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-15686_NHTN.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 278/2245 [00:01<00:07, 266.13it/s]\r 14%|█▎        | 305/2245 [00:01<00:07, 267.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error in  ./npy_ECG/test/22-15687_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-15689_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-18111_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-18112_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-18113_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-18119_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-18121_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-18122_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-18123_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-18125_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-18131_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-18133_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-18171_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-18266_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-18277_NHTN.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 332/2245 [00:01<00:07, 267.20it/s]\r 16%|█▌        | 359/2245 [00:01<00:07, 264.44it/s]\r 17%|█▋        | 387/2245 [00:01<00:06, 267.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error in  ./npy_ECG/test/22-18408_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-18463_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-18466_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-18486_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-18488_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-18523_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-18531_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-18532_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-18557_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-208_NHTN.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 414/2245 [00:01<00:06, 263.71it/s]\r 20%|█▉        | 441/2245 [00:01<00:06, 265.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error in  ./npy_ECG/test/22-21001_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-21002_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-21106_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-21108_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-21143_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-21145_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-21188_NHTN.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 471/2245 [00:01<00:06, 272.64it/s]\r 22%|██▏       | 499/2245 [00:01<00:06, 268.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error in  ./npy_ECG/test/22-21209_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-21277_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-21281_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-21282_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-21312_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-21333_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-21386_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-21400_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-21409_NHTN.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 526/2245 [00:01<00:06, 264.34it/s]\r 25%|██▍       | 553/2245 [00:02<00:06, 265.60it/s]\r 26%|██▌       | 583/2245 [00:02<00:06, 273.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error in  ./npy_ECG/test/22-23904_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-23905_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-23906_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-23912_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-23922_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-23929_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-23931_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-23932_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-23933_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-23934_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-23936_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-23965_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-23972_NHTN.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 611/2245 [00:02<00:06, 271.82it/s]\r 28%|██▊       | 639/2245 [00:02<00:05, 272.89it/s]\r 30%|██▉       | 668/2245 [00:02<00:05, 275.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error in  ./npy_ECG/test/22-24046_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-24080_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-24081_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-24089_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-24090_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-24091_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-24096_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-24126_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-24137_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-24157_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-24165_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-24181_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-24241_NHTN.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 696/2245 [00:02<00:05, 275.35it/s]\r 32%|███▏      | 725/2245 [00:02<00:05, 277.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error in  ./npy_ECG/test/22-24266_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-24274_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-24322_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-24323_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-24324_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-24325_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-24326_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-24327_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-24328_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-26736_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-26737_NHTN.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▎      | 753/2245 [00:02<00:05, 275.09it/s]\r 35%|███▍      | 781/2245 [00:02<00:05, 273.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error in  ./npy_ECG/test/22-26809_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-26810_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-26811_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-26814_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-26815_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-26826_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-26857_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-26927_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-26929_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-26930_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-26937_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-26961_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-26973_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-26974_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-26978_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-26979_NHTN.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 809/2245 [00:03<00:05, 271.40it/s]\r 37%|███▋      | 837/2245 [00:03<00:05, 269.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error in  ./npy_ECG/test/22-27011_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-27012_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-27052_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-27073_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-27080_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-27122_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-27123_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-27124_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-27126_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-27127_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-27137_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-286_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-287_NHTN.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 864/2245 [00:03<00:05, 268.41it/s]\r 40%|███▉      | 892/2245 [00:03<00:04, 270.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error in  ./npy_ECG/test/22-2927_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-29570_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-29571_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-29573_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-29585_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-29590_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-29603_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-29625_NHTN.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 920/2245 [00:03<00:04, 271.95it/s]\r 42%|████▏     | 948/2245 [00:03<00:04, 271.38it/s]\r 43%|████▎     | 976/2245 [00:03<00:04, 272.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error in  ./npy_ECG/test/22-29696_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-29721_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-29783_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-29784_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-29857_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-29858_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-29902_NHTN.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▍     | 1004/2245 [00:03<00:04, 274.86it/s]\r 46%|████▌     | 1032/2245 [00:03<00:04, 275.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error in  ./npy_ECG/test/22-29923_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-29957_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-29958_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-29961_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-29975_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-3043_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-3046_NHTN.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 1060/2245 [00:03<00:04, 273.06it/s]\r 48%|████▊     | 1088/2245 [00:04<00:04, 273.01it/s]\r 50%|████▉     | 1117/2245 [00:04<00:04, 275.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error in  ./npy_ECG/test/22-3198_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-319_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-3240_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-3241_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-32438_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-32457_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-32463_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-3246_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-3247_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-32512_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-32519_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-32540_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-32561_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-32582_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-32634_NHTN.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 1145/2245 [00:04<00:04, 274.54it/s]\r 52%|█████▏    | 1174/2245 [00:04<00:03, 275.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error in  ./npy_ECG/test/22-32698_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-32699_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-32761_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-32782_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-32783_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-32797_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-32810_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-32815_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-32826_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-32828_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-32830_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-32831_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-32907_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-32918_NHTN.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▎    | 1202/2245 [00:04<00:03, 274.28it/s]\r 55%|█████▍    | 1230/2245 [00:04<00:03, 267.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error in  ./npy_ECG/test/22-32956_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-3299_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-33009_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-3300_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-33012_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-3302_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-33034_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-3303_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-33064_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-33067_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-3306_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-33076_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-33078_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-33079_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-33080_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-33081_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-33082_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-3308_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-33090_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-3309_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-33107_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-33108_NHTN.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 1257/2245 [00:04<00:03, 264.83it/s]\r 57%|█████▋    | 1285/2245 [00:04<00:03, 268.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error in  ./npy_ECG/test/22-33113_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-33156_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-33187_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-33226_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-33265_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-33301_NHTN.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 1312/2245 [00:04<00:03, 268.84it/s]\r 60%|█████▉    | 1341/2245 [00:04<00:03, 272.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error in  ./npy_ECG/test/22-33310_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-3342_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-3343_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-3361_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-3362_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-3369_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-3370_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-3371_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-3372_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-3426_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-343_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-346_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-35790_NHTN.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 1369/2245 [00:05<00:03, 273.51it/s]\r 62%|██████▏   | 1397/2245 [00:05<00:03, 271.62it/s]\r 63%|██████▎   | 1425/2245 [00:05<00:03, 263.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error in  ./npy_ECG/test/22-35872_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-358_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-35905_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-35916_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-35922_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-359_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-36053_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-36056_NHTN.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▍   | 1453/2245 [00:05<00:02, 267.03it/s]\r 66%|██████▌   | 1481/2245 [00:05<00:02, 270.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error in  ./npy_ECG/test/22-36191_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-36192_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-36193_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-36224_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-36248_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-36268_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-36269_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-38650_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-38671_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-38672_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-38700_NHTN.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 1510/2245 [00:05<00:02, 274.99it/s]\r 69%|██████▊   | 1538/2245 [00:05<00:02, 273.98it/s]\r 70%|██████▉   | 1566/2245 [00:05<00:02, 272.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error in  ./npy_ECG/test/22-38746_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-38775_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-38776_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-38874_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-38889_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-38902_NHTN.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 1594/2245 [00:05<00:02, 271.87it/s]\r 72%|███████▏  | 1623/2245 [00:05<00:02, 274.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error in  ./npy_ECG/test/22-39009_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-39021_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-39430_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-394_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-39529_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-39580_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-39582_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-39583_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-39584_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-39585_NHTN.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▎  | 1651/2245 [00:06<00:02, 274.39it/s]\r 75%|███████▍  | 1679/2245 [00:06<00:02, 272.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error in  ./npy_ECG/test/22-39647_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-39664_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-39674_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-39688_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-39738_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-39750_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-39780_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-39823_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-39829_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-39847_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-39848_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-39862_NHTN.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 1707/2245 [00:06<00:01, 271.93it/s]\r 77%|███████▋  | 1735/2245 [00:06<00:01, 273.32it/s]\r 79%|███████▊  | 1764/2245 [00:06<00:01, 276.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error in  ./npy_ECG/test/22-401_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-409_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-448_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-496_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-497_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-499_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-503_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-5869_NHTN.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████▉  | 1792/2245 [00:06<00:01, 275.74it/s]\r 81%|████████  | 1820/2245 [00:06<00:01, 275.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error in  ./npy_ECG/test/22-5925_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-5937_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-5939_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-5985_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-5993_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-5996_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-6047_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-6099_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-6101_NHTN.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 1848/2245 [00:06<00:01, 275.45it/s]\r 84%|████████▎ | 1876/2245 [00:06<00:01, 271.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error in  ./npy_ECG/test/22-6171_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-6172_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-6210_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-6211_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-6263_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-6267_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-6351_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-6352_NHTN.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▍ | 1904/2245 [00:07<00:01, 269.69it/s]\r 86%|████████▌ | 1933/2245 [00:07<00:01, 275.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error in  ./npy_ECG/test/22-6368_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-6370_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-6440_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-6469_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-6470_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-6487_NHTN.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 1961/2245 [00:07<00:01, 271.29it/s]\r 89%|████████▊ | 1989/2245 [00:07<00:00, 272.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error in  ./npy_ECG/test/22-6582_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-6591_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-6592_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-6607_NHTN.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████▉ | 2019/2245 [00:07<00:00, 277.83it/s]\r 91%|█████████ | 2047/2245 [00:07<00:00, 275.76it/s]\r 92%|█████████▏| 2076/2245 [00:07<00:00, 277.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error in  ./npy_ECG/test/22-6860_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-6936_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-6959_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-6960_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-6961_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-6962_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-6971_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-6982_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-7025_NHTN.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 2105/2245 [00:07<00:00, 278.03it/s]\r 95%|█████████▌| 2134/2245 [00:07<00:00, 279.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error in  ./npy_ECG/test/22-7100_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-74_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-9491_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-9492_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-9493_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-9520_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-9522_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-9560_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-9561_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-9562_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-9563_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-9565_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-9599_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-95_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-9650_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-9654_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-9655_NHTN.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▋| 2162/2245 [00:07<00:00, 277.11it/s]\r 98%|█████████▊| 2190/2245 [00:08<00:00, 275.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error in  ./npy_ECG/test/22-9686_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-9697_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-9725_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-9726_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-9800_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-9801_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-9812_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-9844_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-9853_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-9854_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-9856_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-9887_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-9898_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-9899_NHTN.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 2218/2245 [00:08<00:00, 269.25it/s]\r100%|██████████| 2245/2245 [00:08<00:00, 265.36it/s]\r100%|██████████| 2245/2245 [00:08<00:00, 271.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error in  ./npy_ECG/test/22-9928_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-9959_NHTN.npy\n",
      "error in  ./npy_ECG/test/22-9962_NHTN.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "npy_path = \"./npy_ECG/test/\"\n",
    "file_list = os.listdir(npy_path)\n",
    "for file in tqdm(file_list):\n",
    "  path = os.path.join(npy_path,file)\n",
    "  ECG_buffer = np.load(path)\n",
    "  error_lead = 0\n",
    "  for i in range(12):\n",
    "    if(ECG_buffer[i].max() == ECG_buffer[i].min()):\n",
    "      error_lead = error_lead +1\n",
    "  if(error_lead>1):\n",
    "    print(\"error in \",path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13 (default, Mar 29 2022, 02:18:16) \n[GCC 7.5.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
