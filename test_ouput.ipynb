{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "%aimport ecg_get_data\n",
    "%aimport Models\n",
    "%aimport train_test_validat\n",
    "%aimport self_attention\n",
    "%aimport ECGplot\n",
    "import Models \n",
    "from train_test_validat import *\n",
    "from self_attention import *\n",
    "import  ecg_get_data \n",
    "import ECGplot\n",
    "\n",
    "import torch\n",
    "import torch.utils.data as Data\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path =  './npy_ECG/' #路径\n",
    "lable_path = './label.npy'\n",
    "test_model_path = \"./model/20220908_133803/best_model_0.pt\"\n",
    "lead_index = ['I', 'II', 'III', 'aVR', 'aVL', 'aVF', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6']\n",
    "EcgChannles_num = 12\n",
    "EcgLength_num = 5000\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(DEVICE)\n",
    "test_model = torch.load(test_model_path).to(DEVICE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = load_data(data_path,EcgChannles_num=EcgChannles_num,EcgLength_num=EcgLength_num)\n",
    "y = load_label(lable_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MaxMinNormalization(x,Max,Min):\n",
    "    x = (x - Min) / (Max - Min);\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = x\n",
    "test_y = y\n",
    "test_x_norm = MAX_MIN_normalization_by_feactures(test_x)\n",
    "test_x_norm = torch.FloatTensor(test_x_norm)  #turn numpy to tensor\n",
    "test_y_norm = torch.LongTensor(test_y)\n",
    "test_dataset = Data.TensorDataset(test_x_norm, test_y_norm)\n",
    "test_dataloader = Data.DataLoader(dataset=test_dataset, batch_size=1, shuffle=False)\n",
    "test_model.eval()\n",
    "acclist = []\n",
    "errlist = []\n",
    "attention_value_timestep = np.zeros((len(x),312))\n",
    "for i,data in enumerate(test_dataloader,0):\n",
    "    inputs,labels = data[0].to(DEVICE),data[1].to(DEVICE)\n",
    "    outputs = test_model(inputs)\n",
    "    #print(labels)\n",
    "    _,pred = outputs.max(1) # 求概率最大值对应的标签\n",
    "    print(\"the label :{labels},pred is {pred}\".format(labels=labels[0],pred=pred[0]))\n",
    "    attention_value_timestep[i] = (((test_model.attention_value2.to('cpu'))[0]).detach().numpy()).sum(axis=0) #将得到的attention值(5000,5000)每行叠加起来，得到（5000，）的attention值\n",
    "    attention_value_timestep[i] = MaxMinNormalization(attention_value_timestep[i],attention_value_timestep[i].max(),attention_value_timestep[i].min())\n",
    "    if(pred == labels):\n",
    "        acclist.append(i) \n",
    "    else:\n",
    "        errlist.append(i)\n",
    "    \n",
    "#attention_value_lead = MaxMinNormalization(attention_value_lead,attention_value_lead.max(),attention_value_lead.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errlist.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_value__each_timestep = np.zeros(EcgLength_num,)\n",
    "factor = int(EcgLength_num/len(attention_value_timestep[0]))\n",
    "for i in range(0,EcgLength_num,factor):\n",
    "    if (i/factor)>=len(attention_value_timestep[0]):\n",
    "        break\n",
    "    attention_value__each_timestep[i:i+factor] = attention_value_timestep[0][int(i/factor)]\n",
    "x_index = np.arange(0,EcgLength_num)\n",
    "fig, axs = plt.subplots(nrows=12, ncols=1, sharex=True,sharey=True,figsize=(90,40), constrained_layout=True)\n",
    "for i,ax in enumerate(axs.flat):\n",
    "    #plot_y = x[1,i,:]*(4.88)\n",
    "    plot_y = np.array(test_x[0,i,:])*4.88\n",
    "    ECGplot.plot_multicolored_line(fig,ax,x = x_index,y= plot_y,color_depend=attention_value__each_timestep,cmap=\"turbo\",y_name = str(lead_index[i])+\" Voltage(mV)\"\n",
    "                                        ,title = lead_index[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26782/26782 [1:51:23<00:00,  4.01it/s]\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "file_path = Path(\"./xml/xml\")\n",
    "file_list = list(file_path.glob('*.xml')) # list(images_path.glob('*.png'))\n",
    "file_list =[str(x) for x in file_list]\n",
    "file_list.sort(key=lambda x:int(x.split('/')[-1].split('_')[0])) #按“/”分割，取最后一个，并把最后后一个按'_'分割，\n",
    "                                                                 #按'_'分割后再取第0个，即为编号，按此排序\n",
    "for file in tqdm(file_list):\n",
    "    ecg = ecg_get_data.get_ECG_form_xml(file,12,5000)\n",
    "    np.save('./npy_ECG_int/'+(file.split('/')[-1].split('.')[0])+\".npy\",ecg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = Path(\"./xml/NHTN/\")\n",
    "file_list = list(file_path.glob('*.xml')) # list(images_path.glob('*.png'))\n",
    "file_list =[str(x) for x in file_list]\n",
    "file_list.sort(key=lambda x:int(x.split('/')[-1].split('_')[0])) #按“/”分割，取最后一个，并把最后后一个按'_'分割，\n",
    "                                                                 #按'_'分割后再取第0个，即为编号，按此排序\n",
    "for file in tqdm(file_list):\n",
    "    ecg = ecg_get_data.get_ECG_form_xml(file,12,5000)\n",
    "    np.save('./npy_ECG_int/'+(file.split('/')[-1].split('.')[0])+\".npy\",ecg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
