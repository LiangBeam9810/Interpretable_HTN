{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ECGDataset \n",
    "import Models \n",
    "import Net\n",
    "from train_test_validat import *\n",
    "from self_attention import *\n",
    "import matplotlib.pyplot as plt\n",
    "import ecg_plot\n",
    "import cam\n",
    "import ECGplot\n",
    "import ECGHandle\n",
    "import torch\n",
    "import torch.utils.data as Data\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import random\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import time\n",
    "import math\n",
    "import os\n",
    "import gc\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "\n",
    "def seed_torch(seed=2023):\n",
    "\trandom.seed(seed)\n",
    "\tos.environ['PYTHONHASHSEED'] = str(seed) # 为了禁止hash随机化，使得实验可复现\n",
    "\tnp.random.seed(seed)\n",
    "\ttorch.manual_seed(seed)\n",
    "\ttorch.cuda.manual_seed(seed)\n",
    "\ttorch.cuda.manual_seed_all(seed) # if you are using multi-GPU.\n",
    "\ttorch.backends.cudnn.benchmark = False \n",
    "\ttorch.backends.cudnn.deterministic = True\n",
    "    # torch.backends.cudnn.enabled = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "EcgChannles_num = 12\n",
    "EcgLength_num = 5000\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(DEVICE)\n",
    "DEVICE = \"cpu\"\n",
    "seed_torch(2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "            orginal   removed diagnose NaN\n",
      "   nums      200082          199997       \n",
      "              HTN             NHTN        \n",
      "   nums       3273           196724       \n",
      "\n",
      "\n",
      "            orginal      removed ID NaN   \n",
      "   nums      199997          199995       \n",
      "              HTN             NHTN        \n",
      "   nums       3273           196722       \n",
      "\n",
      "\n",
      "            orginal            QC         \n",
      "   nums      199995          72845        \n",
      "              HTN             NHTN        \n",
      "   nums       1497           71348        \n",
      "\n",
      "\n",
      "            orginal      filtered ages    \n",
      "   nums      72845           69819        \n",
      "              HTN             NHTN        \n",
      "   nums       1477           68342        \n",
      "\n",
      "\n",
      "            orginal   filtered department \n",
      "   nums      69819           15344        \n",
      "              HTN             NHTN        \n",
      "   nums       1477           13867        \n",
      "\n",
      "\n",
      "     reset num:       10  \n",
      "  ERR labels num:     27  \n",
      "            orginal      correct label    \n",
      "   nums      15344           15344        \n",
      "              HTN             NHTN        \n",
      "   nums       1513           13831        \n",
      "\n",
      "\n",
      "   ERR ages num:      831 \n",
      "            orginal       correct age     \n",
      "   nums      15344           15344        \n",
      "              HTN             NHTN        \n",
      "   nums       1513           13831        \n",
      "\n",
      "\n",
      "            orginal    remove diagnose起搏  \n",
      "   nums      15344           15278        \n",
      "              HTN             NHTN        \n",
      "   nums       1494           13784        \n",
      "           remove HTN     remove NHTN     \n",
      "   nums        19              47         \n",
      "\n",
      "\n",
      "            orginal    remove diagnose房颤  \n",
      "   nums      15278           14747        \n",
      "              HTN             NHTN        \n",
      "   nums       1432           13315        \n",
      "           remove HTN     remove NHTN     \n",
      "   nums        62             469         \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "            orginal    removed duplicated \n",
      "   nums      14747           12475        \n",
      "              HTN             NHTN        \n",
      "   nums       1133           11342        \n"
     ]
    }
   ],
   "source": [
    "data_root = '/workspace/data/Preprocess_HTN/datas_/'\n",
    "ALL_data = pd.read_csv(data_root+'/All_data_handled_ID_range_age_IDimputate.csv',low_memory=False)\n",
    "ALL_data = ECGHandle.change_label(ALL_data)\n",
    "ALL_data = ECGHandle.filter_ID(ALL_data)\n",
    "ALL_data = ECGHandle.filter_QC(ALL_data)\n",
    "ALL_data = ECGHandle.filter_ages(ALL_data,18)\n",
    "ALL_data = ECGHandle.filter_departmentORlabel(ALL_data,'外科')\n",
    "ALL_data = ECGHandle.correct_label(ALL_data)\n",
    "ALL_data = ECGHandle.correct_age(ALL_data)\n",
    "ALL_data = ECGHandle.filter_diagnose(ALL_data,'起搏')\n",
    "ALL_data = ECGHandle.filter_diagnose(ALL_data,'房颤')\n",
    "# ALL_data = ECGHandle.filter_diagnose(ALL_data,'阻滞')\n",
    "ALL_data = ECGHandle.remove_duplicated(ALL_data)\n",
    "ALL_data = ALL_data.rename(columns={'住院号':'ID','年龄':'age','性别':'gender','姓名':'name'}) \n",
    "ALL_data_buffer = ALL_data.copy()\n",
    "seed_torch(2023)\n",
    "ALL_data_buffer = ALL_data_buffer.sample(frac=1).reset_index(drop=True) #打乱顺序\n",
    "# all_dataset = ECGHandle.ECG_Dataset(data_root,ALL_data_buffer,preprocess = True)\n",
    "####################################################################随机选取test\n",
    "test_df,tv_df = Pair_ID(ALL_data,0.2,Range_max=15,pair_num=1)\n",
    "test_dataset = ECGHandle.ECG_Dataset(data_root,test_df,preprocess = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()# 清空显卡cuda\n",
    "NET = [Net.MLBFNet_GUR_o(True,True,True,2,Dropout_rate=0.3),] # type: ignore\n",
    "testmodel = NET[0].to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Models_path = '/workspace/data/Interpretable_HTN/model/20230214_150848/20230214_150848/BestF1_0.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.4674440324306488 acc = 0.8477711397058824\n",
      "f1_macro = 0.8449840280635742\n",
      "f1_micro = 0.8451327433628318\n",
      "f1_binary = 0.8401826484018264\n",
      "Confusion Matrix: \n",
      "[[198  28]\n",
      " [ 42 184]]\n"
     ]
    }
   ],
   "source": [
    "testmodel.load_state_dict(torch.load(Models_path))\n",
    "test_dataloader = Data.DataLoader(dataset=test_dataset, shuffle= False,batch_size=128)\n",
    "test_acc = []   \n",
    "criterion = torch.nn.CrossEntropyLoss() \n",
    "y_true,y_pred,t_out,test_loss,test_acc = eval_model(test_dataloader,criterion,testmodel,DEVICE) # 测试模型\n",
    "print('loss =',test_loss,'acc =',test_acc)\n",
    "print('f1_macro =',f1_score(y_true, y_pred, average='macro')) \n",
    "print('f1_micro =',f1_score(y_true, y_pred, average='micro')) \n",
    "print('f1_binary =',f1_score(y_true, y_pred, average='binary')) \n",
    "cm = confusion_matrix(y_true=y_true, y_pred=y_pred)\n",
    "print(\"Confusion Matrix: \")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9115435821129297\n"
     ]
    }
   ],
   "source": [
    "auc = roc_auc_score(y_true,y_score=((np.array(t_out))[:,1]))\n",
    "print(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testmodel.load_state_dict(torch.load(Models_path))\n",
    "ALL_dataloader = Data.DataLoader(dataset=all_dataset, shuffle= False,batch_size=128)\n",
    "test_acc = []   \n",
    "criterion = torch.nn.CrossEntropyLoss() \n",
    "y_true,y_pred,y_out,test_loss,test_acc = eval_model(ALL_dataloader,criterion,testmodel,DEVICE) # 测试模型\n",
    "print('loss =',test_loss,'acc =',test_acc)\n",
    "print('f1_macro =',f1_score(y_true, y_pred, average='macro')) \n",
    "print('f1_micro =',f1_score(y_true, y_pred, average='micro')) \n",
    "print('f1_binary =',f1_score(y_true, y_pred, average='binary')) \n",
    "cm = confusion_matrix(y_true=y_true, y_pred=y_pred)\n",
    "print(\"Confusion Matrix: \")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GET CAM Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testmodel.eval()\n",
    "# 定义获取梯度的函数\n",
    "fmap_block = list()\n",
    "grad_block = list()\n",
    "\n",
    "# 获取反向的传播图\n",
    "def backward_hook(module, grad_in, grad_out):\n",
    "    grad_block.append(grad_out[0].detach())\n",
    "\n",
    "# 定义获取特征图的函数\n",
    "def farward_hook(module, input, output):\n",
    "    fmap_block.append(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testmodel.load_state_dict(torch.load(Models_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testmodel.layers0.register_forward_hook(farward_hook)\t#正向传播\n",
    "testmodel.layers1.register_forward_hook(farward_hook) \n",
    "testmodel.layers2.register_forward_hook(farward_hook)\t#正向传播\n",
    "testmodel.layers3.register_forward_hook(farward_hook) \n",
    "testmodel.layers4.register_forward_hook(farward_hook)\t#正向传播\n",
    "testmodel.layers5.register_forward_hook(farward_hook) \n",
    "testmodel.layers6.register_forward_hook(farward_hook)\t#正向传播\n",
    "testmodel.layers7.register_forward_hook(farward_hook) \n",
    "testmodel.layers8.register_forward_hook(farward_hook)\t#正向传播\n",
    "testmodel.layers9.register_forward_hook(farward_hook) \n",
    "testmodel.layers10.register_forward_hook(farward_hook)\t#正向传播\n",
    "testmodel.layers11.register_forward_hook(farward_hook) \n",
    "testmodel.conv3.register_forward_hook(farward_hook) \n",
    "testmodel.layers_list_2d[0].register_forward_hook(farward_hook) \n",
    "testmodel.layers_list_2d[1].register_forward_hook(farward_hook) \n",
    "testmodel.layers_list_2d[2].register_forward_hook(farward_hook)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testmodel.layers0.register_full_backward_hook(backward_hook)#反向传播\n",
    "testmodel.layers1.register_full_backward_hook(backward_hook)#反向传播\n",
    "testmodel.layers2.register_full_backward_hook(backward_hook)#反向传播\n",
    "testmodel.layers3.register_full_backward_hook(backward_hook)#反向传播 \n",
    "testmodel.layers4.register_full_backward_hook(backward_hook)#反向传播\n",
    "testmodel.layers5.register_full_backward_hook(backward_hook)#反向传播\n",
    "testmodel.layers6.register_full_backward_hook(backward_hook)#反向传播\n",
    "testmodel.layers7.register_full_backward_hook(backward_hook)#反向传播 \n",
    "testmodel.layers8.register_full_backward_hook(backward_hook)#反向传播\n",
    "testmodel.layers9.register_full_backward_hook(backward_hook)#反向传播\n",
    "testmodel.layers10.register_full_backward_hook(backward_hook)#反向传播\n",
    "testmodel.layers11.register_full_backward_hook(backward_hook)#反向传播\n",
    "testmodel.conv3.register_full_backward_hook(backward_hook)#反向传播\n",
    "testmodel.layers_list_2d[0].register_full_backward_hook(backward_hook)#反向传播\n",
    "testmodel.layers_list_2d[1].register_full_backward_hook(backward_hook)#反向传播\n",
    "testmodel.layers_list_2d[2].register_full_backward_hook(backward_hook)#反向传播"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "branch_fmap_sum_HTN = np.zeros(27)\n",
    "branch_fmap_sum_NHTN = np.zeros(27)\n",
    "\n",
    "for itme in (range(test_dataset.__len__())):\n",
    "    layer2d_vlue_list = list()\n",
    "    # testmodel.layer4.register_forward_hook(farward_hook)\t#正向传播\n",
    "    # testmodel.layer4.register_full_backward_hook(backward_hook)#反向传播\n",
    "    fmap_block = list()\n",
    "    grad_block = list()\n",
    "    inputs,labels = test_dataset.__getitem__(itme)\n",
    "    labels = torch.tensor(labels)\n",
    "    labels = labels.unsqueeze(0) # 在首位添加1维作为batchsize\n",
    "    inputs = inputs.unsqueeze(0) # 在首位添加1维作为batchsize\n",
    "\n",
    "    inputs = inputs.to(DEVICE)\n",
    "    labels = labels.to(DEVICE)  \n",
    "    testmodel.eval()\n",
    "    outputs = testmodel(inputs)\n",
    "    possibility = nn.functional.softmax(outputs,dim=-1)\n",
    "    _,pred = outputs.max(1)     # 求概率最大值对应的标签\n",
    "    loss = outputs[0,pred]      # 网络对应于pred的类别的输出即为loss\n",
    "    loss.backward(retain_graph=True)  #retain_graph=True，目的为是为保留该过程中计算的梯度，后续G网络更新时使用\n",
    "    for i in range(12):\n",
    "        layer2d_vlue = cam.caculate_layer_cam_vlue(fmap_block[i][0].clone().detach().cpu().numpy(),grad_block[15-i][0].clone().detach().cpu().numpy()) #input(C,W) output(original_seq_lenth,)\n",
    "        layer2d_vlue_list.append(layer2d_vlue)\n",
    "    for i in range(12,16):\n",
    "        layer2d_vlue = cam.caculate_layer_cam_vlue_2d(fmap_block[i][0].clone().detach().cpu().numpy(),grad_block[15-i][0].clone().detach().cpu().numpy()) #input(C,H,W) output(lead,original_seq_lenth)\n",
    "        layer2d_vlue_list.append(layer2d_vlue)\n",
    "    if(((labels.tolist())[0]) == torch.tensor(1)):\n",
    "        for i in range(12):\n",
    "            branch_fmap_sum_HTN[i] += layer2d_vlue_list[i].sum()\n",
    "        for i in range(12,24):\n",
    "            branch_fmap_sum_HTN[i] += layer2d_vlue_list[12][i-12,:].sum()\n",
    "        branch_fmap_sum_HTN[24] = fmap_block[13].to('cpu').clone().sum().detach().numpy()\n",
    "        branch_fmap_sum_HTN[25] = fmap_block[14].to('cpu').clone().sum().detach().numpy()\n",
    "        branch_fmap_sum_HTN[26] = fmap_block[15].to('cpu').clone().sum().detach().numpy()\n",
    "    else:\n",
    "        for i in range(12):\n",
    "            branch_fmap_sum_NHTN[i] += layer2d_vlue_list[i].sum()\n",
    "        for i in range(12,24):\n",
    "            branch_fmap_sum_NHTN[i] += layer2d_vlue_list[12][i-12,:].sum()\n",
    "        branch_fmap_sum_NHTN[24] = fmap_block[13].to('cpu').clone().sum().detach().numpy()\n",
    "        branch_fmap_sum_NHTN[25] = fmap_block[14].to('cpu').clone().sum().detach().numpy()\n",
    "        branch_fmap_sum_NHTN[26] = fmap_block[15].to('cpu').clone().sum().detach().numpy()\n",
    "        \n",
    "        \n",
    "        \n",
    "    # # print(\"labels: {}\".format(labels))\n",
    "    # # print(\"predict: {}\".format(pred))\n",
    "    # # loss = outputs[0,pred]      # 网络对应于pred的类别的输出即为loss\n",
    "    # # # loss = (testmodel.last_out)[0,pred]\n",
    "    # # loss.backward(retain_graph=True)  #retain_graph=True，目的为是为保留该过程中计算的梯度，后续G网络更新时使用\n",
    "    # if(((labels.tolist())[0]) == torch.tensor(1)):\n",
    "    #     for i in range(12):\n",
    "    #         branch_fmap_sum_HTN[i]= branch_fmap_sum_HTN[i] + fmap_block[i].to('cpu').sum().detach().numpy()\n",
    "    #         # print(fmap_block[i].size())\n",
    "    #     for i in range(12,24):\n",
    "    #         branch_fmap_sum_HTN[i]= branch_fmap_sum_HTN[i] + fmap_block[12][0,:,i-12].to('cpu').sum().detach().numpy()\n",
    "    #     branch_fmap_sum_HTN[24] = fmap_block[13].to('cpu').sum().detach().numpy()\n",
    "    #     branch_fmap_sum_HTN[25] = fmap_block[14].to('cpu').sum().detach().numpy()\n",
    "    #     branch_fmap_sum_HTN[26] = fmap_block[15].to('cpu').sum().detach().numpy()\n",
    "    # else:\n",
    "    #     for i in range(12):\n",
    "    #         branch_fmap_sum_NHTN[i]= branch_fmap_sum_NHTN[i] + fmap_block[i].to('cpu').sum().detach().numpy()\n",
    "    #         # print(fmap_block[i].size())\n",
    "    #     for i in range(12,24):\n",
    "    #         branch_fmap_sum_NHTN[i]= branch_fmap_sum_NHTN[i] + fmap_block[12][0,:,i-12].to('cpu').sum().detach().numpy()\n",
    "    #     branch_fmap_sum_NHTN[24] = fmap_block[13].to('cpu').sum().detach().numpy()\n",
    "    #     branch_fmap_sum_NHTN[25] = fmap_block[14].to('cpu').sum().detach().numpy()\n",
    "    #     branch_fmap_sum_NHTN[26] = fmap_block[15].to('cpu').sum().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, (ax0, ax1) = plt.subplots(nrows = 2,ncols = 1,figsize=(12,10) ,sharex=True)  # type: ignore\n",
    "\n",
    "leads = ['I', 'II', 'III', 'aVR', 'aVL', 'aVF', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6','I1', 'II1', 'III1', 'aVR1', 'aVL1', 'aVF1', 'V11', 'V21', 'V31', 'V41', 'V51', 'V61',]\n",
    "counts = branch_fmap_sum_HTN[:24].tolist()\n",
    "ax0.bar(leads, counts)\n",
    "ax0.set_ylabel('fmap_sum_HTN')\n",
    "\n",
    "counts = branch_fmap_sum_NHTN[:24].tolist()\n",
    "ax1.bar(leads, counts)\n",
    "ax1.set_ylabel('fmap_sum_NHTN')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax0, ax1) = plt.subplots(nrows = 2,ncols = 1,figsize=(12,10) ,sharex=True)  # type: ignore\n",
    "\n",
    "leads = ['3', '5', '7']\n",
    "counts = branch_fmap_sum_HTN[24:].tolist()\n",
    "ax0.bar(leads, counts)\n",
    "ax0.set_ylabel('fmap_sum_HTN')\n",
    "\n",
    "counts = branch_fmap_sum_NHTN[24:].tolist()\n",
    "ax1.bar(leads, counts)\n",
    "ax1.set_ylabel('fmap_sum_NHTN')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "layer cam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NET = [Net.MLBFNet(num_class= 2,mark=True,res = True,se = True,Dropout_rate = 0.25) ] # type: ignore\n",
    "testmodel = NET[0].to(DEVICE)\n",
    "testmodel.load_state_dict(torch.load(Models_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testmodel.eval()\n",
    "# 定义获取梯度的函数\n",
    "fmap_block = list()\n",
    "grad_block = list()\n",
    "\n",
    "# 获取反向的传播图\n",
    "def backward_hook(module, grad_in, grad_out):\n",
    "    grad_block.append(grad_out[0].detach())\n",
    "\n",
    "# 定义获取特征图的函数\n",
    "def farward_hook(module, input, output):\n",
    "    fmap_block.append(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testmodel.conv3.register_forward_hook(farward_hook)\t#正向传播\n",
    "testmodel.conv3.register_full_backward_hook(backward_hook)#反向传播"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_top_attention_points(fig,axs,x,y,color_depend,cmap = \"jet\",y_name = \"Voltage(mV)\",title=\"\",top_num = 100):\n",
    "    axs.plot(x,y, color='black',linewidth=0.5)\n",
    "    \n",
    "    top_idx=color_depend.argsort()[::-1][0:top_num]\n",
    "    axs.scatter(top_idx, y[top_idx],s=2,c='r')\n",
    "    #fig.colorbar(line, ax=axs)\n",
    "    axs.set_xlim(x.min(), x.max())\n",
    "    axs.set_ylim(-3500, +3500)\n",
    "\n",
    "    axs.set_aspect(0.2)#用于设置轴缩放的方面，即y-unit与x-unit的比率\n",
    "    axs.xaxis.set_major_locator(plt.MultipleLocator(100))# type: ignore # 100*0.002s=0.2s = 5格\n",
    "    axs.xaxis.set_minor_locator(plt.MultipleLocator(20)) # type: ignore # 20*0.002=0.004S = 1格\n",
    "    axs.yaxis.set_major_locator(plt.MultipleLocator(500))# type: ignore # 0.1uv*500 = 0.5ms = 5格\n",
    "    axs.yaxis.set_minor_locator(plt.MultipleLocator(100))# type: ignore # 0.1uv*100 =0.1ms = 1格 \n",
    "\n",
    "    #axs.xaxis.set_major_formatter(plt.NullFormatter()) #x轴不显示刻度值/lable per 0.2s\n",
    "    axs.xaxis.set_major_formatter(lambda x, pos: str(round(0.2*(x/100.0),2))) #x轴 lable per 0.2s\n",
    "    axs.yaxis.set_major_formatter(lambda x, pos: str(x/1000.0)) # label per '0.5 mv'，turn uV to mv\n",
    "\n",
    "    axs.grid(which='major', axis='x', linewidth=0.3, linestyle='-', color='b')\n",
    "    axs.grid(which='minor', axis='x', linewidth=0.1, linestyle='-', color='b')\n",
    "    axs.grid(which='major', axis='y', linewidth=0.3, linestyle='-', color='b')\n",
    "    axs.grid(which='minor', axis='y', linewidth=0.1, linestyle='-', color='b')\n",
    "    axs.set_ylabel(y_name)\n",
    "    axs.set_title(title)\n",
    "    axs.grid(True, which='both')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for itme in tqdm(range(10)):\n",
    "    fmap_block = list()\n",
    "    grad_block = list()\n",
    "    inputs,labels = test_dataset.__getitem__(itme)\n",
    "    ECGFilename = (test_dataset.infos.iloc[itme]['ECGFilename'])\n",
    "    labels = labels.unsqueeze(0) # 在首位添加1维作为batchsize\n",
    "    inputs = inputs.unsqueeze(0) # 在首位添加1维作为batchsize\n",
    "    testmodel.eval()\n",
    "    inputs = inputs.to(DEVICE)\n",
    "    labels = labels.to(DEVICE)  \n",
    "\n",
    "    outputs = testmodel(inputs)\n",
    "    _,pred = outputs.max(1)     # 求概率最大值对应的标签\n",
    "    # print(\"labels: {}\".format(labels))\n",
    "    # print(\"predict: {}\".format(pred))\n",
    "    loss = outputs[0,pred]      # 网络对应于pred的类别的输出即为loss\n",
    "    # loss = (testmodel.last_out)[0,pred]\n",
    "    loss.backward(retain_graph=True)  #retain_graph=True，目的为是为保留该过程中计算的梯度，后续G网络更新时使用\n",
    "    fmap = (fmap_block[0][0]).to('cpu').detach().numpy()\n",
    "    gradmap = (grad_block[0][0]).to('cpu').detach().numpy()\n",
    "    layer2d_vlue = cam.caculate_layer_cam_vlue_2d(fmap,gradmap)\n",
    "    lead_index = ['I', 'II', 'III', 'aVR', 'aVL', 'aVF', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6']\n",
    "    x_index = np.arange(0,EcgLength_num)\n",
    "    fig, axs = plt.subplots(nrows=6, ncols=2, sharex=True,sharey=True,figsize=(50,60), constrained_layout=True)\n",
    "    ecg_data = (inputs[0]).to('cpu')\n",
    "    for i,ax in enumerate(axs.flat):  # type: ignore\n",
    "        attention_value_each_timestep = layer2d_vlue[i]\n",
    "        #plot_y = x[1,i,:]*(4.88)\n",
    "        plot_y = np.array(ecg_data[i]*3500.)\n",
    "        ECGplot.plot_multicolored_line(fig,ax,x = x_index,y= plot_y,color_depend=attention_value_each_timestep,cmap=\"jet\",y_name = str(lead_index[i])+\" Voltage(mV)\",title = lead_index[i])\n",
    "        plot_top_attention_points(fig,ax,x = x_index,y= plot_y,color_depend=attention_value_each_timestep,cmap=\"jet\",y_name = str(lead_index[i])+\" Voltage(mV)\",title = lead_index[i],top_num=500)\n",
    "    plt.savefig('/workspace/data/Interpretable_HTN/model/20230131_114246/20230131_114246/'+'/'+str(ECGFilename)+'_'+str(labels[0].tolist())+'_'+str(pred[0].tolist())+'_''.jpg', bbox_inches='tight',dpi = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# single sampel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NET = [Net.MLBFNet(num_class=2,mark=True,res = True,se = True,Dropout_rate = 0.3) ] # type: ignore\n",
    "testmodel = NET[0].to(DEVICE)\n",
    "testmodel.load_state_dict(torch.load(Models_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义获取梯度的函数\n",
    "fmap_block = list()\n",
    "grad_block = list()\n",
    "\n",
    "# 获取反向的传播图\n",
    "def backward_hook(module, grad_in, grad_out):\n",
    "    # print('backward_hook ',len(grad_out),grad_out[0].shape)\n",
    "    grad_block.append(grad_out[0].clone().cpu().detach())\n",
    "\n",
    "# 定义获取特征图的函数\n",
    "def farward_hook(module, input, output):\n",
    "    # print('farward_hook ',output.shape)\n",
    "    fmap_block.append(output.clone().cpu().detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 2\n",
    "\n",
    "testmodel = NET[0].to(DEVICE)\n",
    "testmodel.load_state_dict(torch.load(Models_path))\n",
    "\n",
    "# testmodel.conv3.register_forward_hook(farward_hook)\t#正向传播\n",
    "# testmodel.conv3.register_full_backward_hook(backward_hook)#反向传播\n",
    "testmodel.conv3.register_forward_hook(farward_hook)\t#正向传播\n",
    "testmodel.conv3.register_full_backward_hook(backward_hook)#反向传播\n",
    "\n",
    "\n",
    "inputs,labels = test_dataset.__getitem__(index)\n",
    "info =test_dataset.infos.iloc[index]\n",
    "# print(inputs,info)\n",
    "testmodel.eval()\n",
    "fmap_block = list()\n",
    "grad_block = list()\n",
    "\n",
    "labels = labels.unsqueeze(0) # 在首位添加1维作为batchsize\n",
    "inputs = inputs.unsqueeze(0) # 在首位添加1维作为batchsize\n",
    "\n",
    "inputs = inputs.to(DEVICE)\n",
    "labels = labels.to(DEVICE)  \n",
    "\n",
    "outputs = testmodel(inputs)\n",
    "# print('outputs',outputs)\n",
    "_,pred = outputs.max(1)     # 求概率最大值对应的标签\n",
    "possibility = nn.functional.softmax(outputs,dim=-1)\n",
    "print(\"labels: {}\".format(labels))\n",
    "print(\"predict: {}\".format(pred))\n",
    "print(\"possibility: {}\".format(possibility))\n",
    "loss = outputs[0,pred]      # 网络对应于pred的类别的输出即为loss\n",
    "loss.backward(retain_graph=True)  #retain_graph=True，目的为是为保留该过程中计算的梯度，后续G网络更新时使用\n",
    "fmap = (fmap_block[0][0]).to('cpu').detach().numpy()\n",
    "gradmap = (grad_block[0][0]).to('cpu').detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer2d_vlue = cam.caculate_layer_cam_vlue_2d(fmap,gradmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer2d_vlue.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer2d_vlue = cam.caculate_layer_cam_vlue_2d(fmap,gradmap)\n",
    "lead_index = ['I', 'II', 'III', 'aVR', 'aVL', 'aVF', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6']\n",
    "x_index = np.arange(0,12)\n",
    "fig, axs = plt.subplots(nrows=4, ncols=3, sharex=True,sharey=True,figsize=(45,25), constrained_layout=True,dpi =300)\n",
    "ecg_data,_ = test_dataset.__getitem__(index)\n",
    "\n",
    "cmap = 'OrRd' \n",
    "colors = ECGplot.color_map(layer2d_vlue, cmap)#相当于归一化\n",
    "\n",
    "for i,ax in enumerate(axs.flat):  # type: ignore\n",
    "    plot_y = np.array(ecg_data[i]*5000.)\n",
    "    x = np.arange(0,5000)\n",
    "    ECGplot.plot_ECG_line(fig,ax,x = x,y= plot_y,y_name = str(lead_index[i])+\" Voltage(mV)\",title = lead_index[i])\n",
    "    for j in x:\n",
    "        ax.axvline(x=j,alpha=0.1,color=colors[i,j]) #第i导联 第j个时间点的importance value\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NET = [Net.MLBFNet_GUR(mark = True,res = True,se = True,Dropout_rate = 0.3) ] # type: ignore\n",
    "testmodel = NET[0].to(DEVICE)\n",
    "Models_path = '/workspace/data/Interpretable_HTN/model/20230201_143012/20230201_143012/parameter_EarlyStoping_2.pt'\n",
    "testmodel.load_state_dict(torch.load(Models_path))\n",
    "save_root = '/workspace/data/Interpretable_HTN/model/20230201_143012/20230201_143012/parameter_EarlyStoping_2/'\n",
    "\n",
    "# 定义获取梯度的函数\n",
    "fmap_block = list()\n",
    "grad_block = list()\n",
    "\n",
    "# 获取反向的传播图\n",
    "def backward_hook(module, grad_in, grad_out):\n",
    "    print('backward_hook ',len(grad_out),grad_out[0].shape)\n",
    "    grad_block.append(grad_out[0].clone().cpu().detach())\n",
    "\n",
    "# 定义获取特征图的函数\n",
    "def farward_hook(module, input, output):\n",
    "    print('farward_hook ',output.shape)\n",
    "    fmap_block.append(output.clone().cpu().detach())\n",
    "    \n",
    "    \n",
    "for index in range(test_dataset.__len__()):\n",
    "    testmodel = NET[0].to(DEVICE)\n",
    "    \n",
    "    testmodel.load_state_dict(torch.load(Models_path))\n",
    "\n",
    "    # testmodel.conv3.register_forward_hook(farward_hook)\t#正向传播\n",
    "    # testmodel.conv3.register_full_backward_hook(backward_hook)#反向传播\n",
    "    testmodel.conv3.register_forward_hook(farward_hook)\t#正向传播\n",
    "    testmodel.conv3.register_full_backward_hook(backward_hook)#反向传播\n",
    "\n",
    "\n",
    "    inputs,labels = test_dataset.__getitem__(index)\n",
    "    info =test_dataset.infos.iloc[index]\n",
    "    # print(inputs,info)\n",
    "    testmodel.eval()\n",
    "    fmap_block = list()\n",
    "    grad_block = list()\n",
    "\n",
    "    labels = labels.unsqueeze(0) # 在首位添加1维作为batchsize\n",
    "    inputs = inputs.unsqueeze(0) # 在首位添加1维作为batchsize\n",
    "\n",
    "    inputs = inputs.to(DEVICE)\n",
    "    labels = labels.to(DEVICE)  \n",
    "\n",
    "    outputs = testmodel(inputs)\n",
    "    # print('outputs',outputs)\n",
    "    _,pred = outputs.max(1)     # 求概率最大值对应的标签\n",
    "    possibility = nn.functional.softmax(outputs,dim=-1)\n",
    "    print(\"labels: {}\".format(labels))\n",
    "    print(\"predict: {}\".format(pred))\n",
    "    print(\"possibility: {}\".format(possibility))\n",
    "    loss = outputs[0,pred]      # 网络对应于pred的类别的输出即为loss\n",
    "    loss.backward(retain_graph=True)  #retain_graph=True，目的为是为保留该过程中计算的梯度，后续G网络更新时使用\n",
    "    fmap = (fmap_block[0][0]).to('cpu').detach().numpy()\n",
    "    gradmap = (grad_block[0][0]).to('cpu').detach().numpy()\n",
    "\n",
    "    layer2d_vlue = cam.caculate_layer_cam_vlue_2d(fmap,gradmap)\n",
    "    lead_index = ['I', 'II', 'III', 'aVR', 'aVL', 'aVF', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6']\n",
    "    x_index = np.arange(0,12)\n",
    "    fig, axs = plt.subplots(nrows=4, ncols=3, sharex=True,sharey=True,figsize=(45,25), constrained_layout=True,dpi =100)\n",
    "    ecg_data,_ = test_dataset.__getitem__(index)\n",
    "\n",
    "    cmap = 'OrRd' \n",
    "    colors = ECGplot.color_map(layer2d_vlue, cmap)#相当于归一化\n",
    "\n",
    "    for i,ax in enumerate(axs.flat):  # type: ignore\n",
    "        plot_y = np.array(ecg_data[i]*5000.)#缩放\n",
    "        t = np.arange(0,5000)\n",
    "        ECGplot.plot_ECG_line(fig,ax,x = t,y= plot_y,y_name = str(lead_index[i])+\" Voltage(mV)\",title = lead_index[i])\n",
    "        for j in t:\n",
    "            ax.axvline(x=j,alpha=0.1,color=colors[i,j]) #第i导联 第j个时间点的importance value\n",
    "    plt.savefig(save_root+'/'+info['ECGFilename']+'_'+str(labels[0].tolist())+'_'+str(pred[0].tolist())+'_'+'conv3'+'.png', bbox_inches='tight',dpi = 200)   \n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NET = [Net.MLBFNet(num_class = 2,mark = True,res = True,se = True,Dropout_rate = 0.3) ] # type: ignore\n",
    "testmodel = NET[0].to(DEVICE)\n",
    "Models_path = '/workspace/data/Interpretable_HTN/model/20230131_114246/20230131_114246/parameter_EarlyStoping_0.pt'\n",
    "testmodel.load_state_dict(torch.load(Models_path))\n",
    "save_root = '/workspace/data/Interpretable_HTN/model/20230131_114246/20230131_114246/parameter_EarlyStoping_0/'\n",
    "\n",
    "# 定义获取梯度的函数\n",
    "fmap_block = list()\n",
    "grad_block = list()\n",
    "\n",
    "# 获取反向的传播图\n",
    "def backward_hook(module, grad_in, grad_out):\n",
    "    print('backward_hook ',len(grad_out),grad_out[0].shape)\n",
    "    grad_block.append(grad_out[0].clone().cpu().detach())\n",
    "\n",
    "# 定义获取特征图的函数\n",
    "def farward_hook(module, input, output):\n",
    "    print('farward_hook ',output.shape)\n",
    "    fmap_block.append(output.clone().cpu().detach())\n",
    "    \n",
    "    \n",
    "for index in range(20):\n",
    "    NET = [Net.MLBFNet(num_class = 2,mark = True,res = True,se = True,Dropout_rate = 0.3) ] # type: ignore\n",
    "    testmodel = NET[0].to(DEVICE)\n",
    "    testmodel.load_state_dict(torch.load(Models_path))\n",
    "\n",
    "    # testmodel.conv3.register_forward_hook(farward_hook)\t#正向传播\n",
    "    # testmodel.conv3.register_full_backward_hook(backward_hook)#反向传播\n",
    "    testmodel.conv3.register_forward_hook(farward_hook)\t#正向传播\n",
    "    testmodel.conv3.register_full_backward_hook(backward_hook)#反向传播\n",
    "\n",
    "\n",
    "    inputs,labels = test_dataset.__getitem__(index)\n",
    "    info =test_dataset.infos.iloc[index]\n",
    "    # print(inputs,info)\n",
    "    testmodel.eval()\n",
    "    fmap_block = list()\n",
    "    grad_block = list()\n",
    "\n",
    "    labels = labels.unsqueeze(0) # 在首位添加1维作为batchsize\n",
    "    inputs = inputs.unsqueeze(0) # 在首位添加1维作为batchsize\n",
    "\n",
    "    inputs = inputs.to(DEVICE)\n",
    "    labels = labels.to(DEVICE)  \n",
    "\n",
    "    outputs = testmodel(inputs)\n",
    "    # print('outputs',outputs)\n",
    "    _,pred = outputs.max(1)     # 求概率最大值对应的标签\n",
    "    possibility = nn.functional.softmax(outputs,dim=-1)\n",
    "    print(\"labels: {}\".format(labels))\n",
    "    print(\"predict: {}\".format(pred))\n",
    "    print(\"possibility: {}\".format(possibility))\n",
    "    loss = outputs[0,pred]      # 网络对应于pred的类别的输出即为loss\n",
    "    loss.backward(retain_graph=True)  #retain_graph=True，目的为是为保留该过程中计算的梯度，后续G网络更新时使用\n",
    "    fmap = (fmap_block[0][0]).to('cpu').detach().numpy()\n",
    "    gradmap = (grad_block[0][0]).to('cpu').detach().numpy()\n",
    "\n",
    "    layer2d_vlue = cam.caculate_layer_cam_vlue_2d(fmap,gradmap)\n",
    "    lead_index = ['I', 'II', 'III', 'aVR', 'aVL', 'aVF', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6']\n",
    "    x_index = np.arange(0,12)\n",
    "    fig, axs = plt.subplots(nrows=4, ncols=3, sharex=True,sharey=True,figsize=(45,25), constrained_layout=True,dpi =100)\n",
    "    ecg_data,_ = test_dataset.__getitem__(index)\n",
    "\n",
    "    cmap = 'OrRd' \n",
    "    colors = ECGplot.color_map(layer2d_vlue, cmap)#相当于归一化\n",
    "\n",
    "    for i,ax in enumerate(axs.flat):  # type: ignore\n",
    "        plot_y = np.array(ecg_data[i]*5000.)#缩放\n",
    "        t = np.arange(0,5000)\n",
    "        ECGplot.plot_ECG_line(fig,ax,x = t,y= plot_y,y_name = str(lead_index[i])+\" Voltage(mV)\",title = lead_index[i])\n",
    "        for j in t:\n",
    "            ax.axvline(x=j,alpha=0.1,color=colors[i,j]) #第i导联 第j个时间点的importance value\n",
    "    plt.savefig(save_root+'/'+info['ECGFilename']+'_'+str(labels[0].tolist())+'_'+str(pred[0].tolist())+'_'+'conv3'+'.png', bbox_inches='tight',dpi = 200)  \n",
    "    plt.close()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
